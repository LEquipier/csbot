# -*- coding: utf-8 -*-
"""
build_database.py

æ•´åˆç‰ˆæœ¬ï¼šæ”¯æŒä¸²è¡Œå’Œå¤šçº¿ç¨‹ä¸¤ç§æ¨¡å¼

ä¸»è¦ç‰¹ç‚¹ï¼š
1. ä¸¥æ ¼1ç§’é—´éš”APIé™åˆ¶
2. æ”¯æŒä¸²è¡Œå¤„ç†ï¼ˆç¨³å®šï¼‰å’Œå¤šçº¿ç¨‹å¤„ç†ï¼ˆå¿«é€Ÿï¼‰
3. æ™ºèƒ½é‡è¯•å’Œé”™è¯¯å¤„ç†
4. è¯¦ç»†è¿›åº¦æ˜¾ç¤º
5. å®Œå…¨APIåˆè§„

ç›®æ ‡ï¼š
- å®æ—¶è®°å½•å½“å‰æ—¶åˆ»çš„åˆ€å‹æ•°æ®
- æ¯æ¬¡è¿è¡Œåªè®°å½•å½“å‰æ•°æ®ï¼Œä¸è·å–å†å²æ•°æ®
- æŒ‰ç…§æŒ‡å®šç›®å½•ç»“æ„ä¿å­˜ï¼šdataset/åŒ•é¦–/åŒ•é¦–ç±»å‹/çš®è‚¤ç±»å‹.csv
- å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨åˆ™åˆ›å»ºï¼Œå­˜åœ¨åˆ™è¿½åŠ æ–°è¡Œ

æ•°æ®ç»“æ„ï¼š
- æ—¶é—´ï¼šåŸºäºåŒ—äº¬æ—¶é—´çš„ç°å®è®°å½•æ—¶é—´ï¼Œç²¾ç¡®åˆ°åˆ†é’Ÿ
- BUFF_sell_price: BUFFå¹³å°æœ€ä½å”®ä»·
- YYYP_sell_price: YYYPå¹³å°æœ€ä½å”®ä»·  
- BUFF_buy_price: BUFFå¹³å°æ±‚è´­ä»·æ ¼
- YYYP_buy_price: YYYPå¹³å°æ±‚è´­ä»·æ ¼
- BUFF_sell_num: BUFFå¹³å°åœ¨å”®æ•°é‡
- YYYP_sell_num: YYYPå¹³å°åœ¨å”®æ•°é‡
- BUFF_buy_num: BUFFå¹³å°æ±‚è´­æ•°é‡
- YYYP_buy_num: YYYPå¹³å°æ±‚è´­æ•°é‡
- BUFF_statistic: BUFFå¹³å°æˆäº¤é‡
- YYYP_statistic: YYYPå¹³å°æˆäº¤é‡
- good_id: å•†å“ID


"""

import os
import json
import pandas as pd
import numpy as np
from typing import Dict, List, Any, Tuple, Union
from datetime import datetime, timezone, timedelta
import sys
import time
import glob
import re
import random
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
from queue import Queue

# å¯¼å…¥CSQAQå®¢æˆ·ç«¯
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from CSQAQ import CsqaqClient
from config import API_TOKEN

# éœ€è¦è¿‡æ»¤çš„å…³é”®è¯ï¼ˆåœ¨æ‰€æœ‰æ¿å—ä¸­éƒ½ä¼šè¢«å¿½ç•¥ï¼‰
FILTER_KEYWORDS = ["å°èŠ±", "æŒ‚ä»¶", "éŸ³ä¹ç›’", "æ¶‚é¸¦"]

# éœ€è¦è¿‡æ»¤çš„å¤–è§‚å“è´¨ï¼ˆåœ¨æŒ‡å®šæ¿å—ä¸­ä¼šè¢«å¿½ç•¥ï¼‰
EXTERIOR_FILTER_KEYWORDS = ["æˆ˜ç—•ç´¯ç´¯", "ç ´æŸä¸å ª"]

# éœ€è¦è¿‡æ»¤çš„StatTrakç‰©å“ï¼ˆåœ¨æŒ‡å®šæ¿å—ä¸­ä¼šè¢«å¿½ç•¥ï¼‰
STATTRAK_FILTER_CATEGORIES = ["åŒ•é¦–", "æ‰‹æª", "æ­¥æª", "æ‰‹å¥—"]

# æ’é™¤å…³é”®è¯ï¼ˆé¿å…äº¤å‰åŒ¹é…ï¼‰
EXCLUDE_KEYWORDS = {
    "åˆºåˆ€": ["M9åˆºåˆ€", "M9 åˆºåˆ€"],  # åˆºåˆ€ç¼“å­˜æ’é™¤M9åˆºåˆ€
    "M9åˆºåˆ€": ["åˆºåˆ€"],  # M9åˆºåˆ€ç¼“å­˜æ’é™¤æ™®é€šåˆºåˆ€å’Œè‡ªèº«ï¼ˆé¿å…é‡å¤ï¼‰
    "è´è¶åˆ€": [],  # è´è¶åˆ€æ²¡æœ‰éœ€è¦æ’é™¤çš„
    "é²ä¼ŠçŒåˆ€": [],
    "å¼¯åˆ€": [],
    "æŠ˜å åˆ€": [],
    "ç©¿è‚ åˆ€": [],
    "çŒæ€è€…åŒ•é¦–": [],
    "çˆªå­åˆ€": [],
    "æš—å½±åŒåŒ•": [],
    "çŸ­å‰‘": [],
    "ç†Šåˆ€": [],
    "æŠ˜åˆ€": [],
    "é”¯é½¿çˆªåˆ€": [],
    "æµ·è±¹çŸ­åˆ€": [],
    "ç³»ç»³åŒ•é¦–": [],
    "æ±‚ç”ŸåŒ•é¦–": [],
    "æµæµªè€…åŒ•é¦–": [],
    "éª·é«…åŒ•é¦–": [],
    "å»“å°”å–€åˆ€": [],
}

# åˆ€å‹å…³é”®è¯æ˜ å°„
KNIFE_KEYWORDS = {
    "è´è¶åˆ€": ["è´è¶åˆ€"],
    "é²ä¼ŠçŒåˆ€": ["é²ä¼ŠçŒåˆ€"],
    "å¼¯åˆ€": ["å¼¯åˆ€"],
    "æŠ˜å åˆ€": ["æŠ˜å åˆ€"],
    "ç©¿è‚ åˆ€": ["ç©¿è‚ åˆ€"],
    "çŒæ€è€…åŒ•é¦–": ["çŒæ€è€…åŒ•é¦–"],
    "M9åˆºåˆ€": ["M9"],
    "åˆºåˆ€": ["åˆºåˆ€"],
    "çˆªå­åˆ€": ["çˆªå­åˆ€"],
    "æš—å½±åŒåŒ•": ["æš—å½±åŒåŒ•"],
    "çŸ­å‰‘": ["çŸ­å‰‘"],
    "ç†Šåˆ€": ["ç†Šåˆ€"],
    "æŠ˜åˆ€": ["æŠ˜åˆ€"],
    "é”¯é½¿çˆªåˆ€": ["é”¯é½¿çˆªåˆ€"],
    "æµ·è±¹çŸ­åˆ€": ["æµ·è±¹çŸ­åˆ€"],
    "ç³»ç»³åŒ•é¦–": ["ç³»ç»³åŒ•é¦–"],
    "æ±‚ç”ŸåŒ•é¦–": ["æ±‚ç”ŸåŒ•é¦–"],
    "æµæµªè€…åŒ•é¦–": ["æµæµªè€…åŒ•é¦–"],
    "éª·é«…åŒ•é¦–": ["éª·é«…åŒ•é¦–"],
    "å»“å°”å–€åˆ€": ["å»“å°”å–€åˆ€"]
}

# æ–°å¢ç‰©å“ç±»åˆ«å…³é”®è¯æ˜ å°„
ITEM_CATEGORIES = {
    # åŒ•é¦–ç±»åˆ«
    "åŒ•é¦–": KNIFE_KEYWORDS,
    
    # æ¢å‘˜ç±»åˆ«
    "æ¢å‘˜": {
        "æ¢å‘˜": [
            "æ®‹é…·çš„è¾¾é‡Œå°”çˆµå£«ï¼ˆè¿ˆé˜¿å¯†ï¼‰", "æŒ‡æŒ¥å®˜é»›ç»´è¾¾Â·è´¹å°”å—å¾·æ–¯ï¼ˆæŠ¤ç›®é•œï¼‰", "å‡ºé€ƒçš„è¨è‰",
            "æŒ‡æŒ¥å®˜å¼—å…°å…‹Â·å·´é²å¾·ï¼ˆæ¹¿è¢œï¼‰", "è€ K", "æ®‹é…·çš„è¾¾é‡Œå°”çˆµå£«ï¼ˆè’å™ªï¼‰",
            "æ®‹é…·çš„è¾¾é‡Œå°”çˆµå£«ï¼ˆçš‡å®¶ï¼‰", "è–‡å¸•å§ï¼ˆé©æ–°æ´¾ï¼‰", "D ä¸­é˜Ÿå†›å®˜",
            "æ®‹é…·çš„è¾¾é‡Œå°”çˆµå£«ï¼ˆå¤´ç›–éª¨ï¼‰", "é™†å†›ä¸­å°‰æ™®é‡Œç±³ç½—", "æ®‹é…·çš„è¾¾é‡Œå°”ï¼ˆç©·é¬¼ï¼‰",
            "æ®‹é…·çš„è¾¾é‡Œå°”çˆµå£«ï¼ˆæ²‰é»˜ï¼‰", "å°å‡¯å¤«", "ä¸Šæ ¡æ›¼æˆˆæ–¯Â·è¾¾æ¯”è¥¿",
            "å…‹æ‹‰æ–¯æ²ƒç‰¹ï¼ˆä¸‰åˆ†ç†Ÿï¼‰", "ç²¾é”æ•å…½è€…ç´¢å°”æ›¼", "çˆ±å¨ƒç‰¹å·¥",
            "ä¸­é˜Ÿé•¿é²æ²™å°”Â·å‹’åº“æ‰˜", "åŒ–å­¦é˜²å®³ä¸Šå°‰", "æ•å…½è€…", "é£è´¼æ³¢å…¹æ›¼",
            '"è“è“" é“…å¼¹', "é—å¿˜è€…å…‹æ‹‰æ–¯æ²ƒç‰¹", "ä¸›æ—åæŠ—è€…", "æµ·å†›ä¸Šå°‰é‡Œå…‹ç´¢å°”",
            "æ•å…½è€…ï¼ˆæŒ‘è¡…è€…ï¼‰", "å†›å®˜é›…å…‹Â·è´å°”ç‰¹æœ—", 'æŒ‡æŒ¥å®˜ æ¢… "æå¯’" è´¾ç±³æ£®',
            "ä¸­å°‰æ³•æ´›ï¼ˆæŠ±æ ‘äººï¼‰", "å¾·å›½ç‰¹ç§éƒ¨é˜Ÿçªå‡»é˜Ÿ", "ä¸­å°‰é›·å…‹æ–¯Â·å…‹é‡Œå¥‡",
            "åŒ–å­¦é˜²å®³ä¸“å®¶", '"åŒ»ç”Ÿ" ç½—æ›¼è¯ºå¤«', "ç”Ÿç‰©é˜²å®³ä¸“å®¶",
            "æµ·è±¹çªå‡»é˜Ÿç¬¬å…­åˆ†é˜Ÿå£«å…µ", "äºšè¯ºï¼ˆé‡è‰ï¼‰", "è¡—å¤´å£«å…µ", "å†›å£«é•¿ç‚¸å¼¹æ£®",
            'çº¦ç¿° "èŒƒÂ·æµ·ä¼¦" å¡æ–¯å…‹', "ç¬¬ä¸€ä¸­å°‰æ³•æ´›", "è”é‚¦è°ƒæŸ¥å±€ï¼ˆFBIï¼‰ç‰¹è­¦", "ç²¾è‹±ç©†å“ˆé‡Œå…‹å…ˆç”Ÿ",
            "å†›åŒ»å°‘å°‰", "B ä¸­é˜ŸæŒ‡æŒ¥å®˜", "å‡†å°‰", "è¿ˆå…‹Â·èµ›å¼—æ–¯", "é»‘ç‹¼",
            '"ä¸¤æ¬¡" éº¦è€ƒä¼Š', "çº¢è¡«åˆ—èµ", "å¾·æ‹‰æˆˆç±³å°”", "å‡†å¤‡å°±ç»ªçš„åˆ—èµ",
            "é“…å¼¹", "é©¬å°”åº“æ–¯Â·æˆ´åŠ³", "å‡¤å‡°æˆ˜å£«", "å¥¥è¥¿ç‘æ–¯", "é©¬å…‹è¥¿å§†æ–¯",
            "æ²™å“ˆé©¬ç‰¹æ•™æˆ", "åœ°é¢å›å†›"
        ],
    },
    
    # æ‰‹æªç±»åˆ«
    "æ‰‹æª": {
        "USP æ¶ˆéŸ³ç‰ˆ": ["USP æ¶ˆéŸ³ç‰ˆ"],
        "æ ¼æ´›å…‹ 18 å‹": ["æ ¼æ´›å…‹ 18 å‹"],
        "æ²™æ¼ ä¹‹é¹°": ["æ²™æ¼ ä¹‹é¹°"],
    },
    
    # æ­¥æªç±»åˆ«
    "æ­¥æª": {
        "AK-47": ["AK-47"],
        "M4A1": ["M4A1"],
        "M4A4": ["M4A4"],
        "AWP": ["AWP"],
    },
    
    # æ‰‹å¥—ç±»åˆ«
    "æ‰‹å¥—": {
        "è¿åŠ¨æ‰‹å¥—": ["è¿åŠ¨æ‰‹å¥—"],
        "ä¸“ä¸šæ‰‹å¥—": ["ä¸“ä¸šæ‰‹å¥—"],
        "æ‘©æ‰˜æ‰‹å¥—": ["æ‘©æ‰˜æ‰‹å¥—"],
    },
}

# åˆ€å‹æ¨¡ç‰ˆé…ç½® - æŒ‡å®šæ¯ä¸ªåˆ€å‹è¦ç›‘æµ‹çš„ç‰¹å®šæ¨¡ç‰ˆ
# æ ¼å¼ï¼š{åˆ€å‹åç§°: [æ¨¡ç‰ˆåç§°åˆ—è¡¨]}
# å¦‚æœæŸä¸ªåˆ€å‹ä¸åœ¨è¿™ä¸ªé…ç½®ä¸­ï¼Œåˆ™ç›‘æµ‹è¯¥åˆ€å‹çš„æ‰€æœ‰æ¨¡ç‰ˆ
KNIFE_TEMPLATES = {
    "è´è¶åˆ€": [
        "æ¸å˜ä¹‹è‰²",  # Fade
        "å¤šæ™®å‹’",    # Doppler
        "ä¼½é©¬å¤šæ™®å‹’", # Gamma Doppler
        "è™ç‰™",      # Tiger Tooth
        "é»‘è‰²å±‚å‹æ¿", # Black Laminate
        "å± å¤«",      # Slaughter
        "ä¼ è¯´",      # Legend
    ],
    "M9åˆºåˆ€": [
        "æ¸å˜ä¹‹è‰²",  # Fade
        "å¤šæ™®å‹’",    # Doppler
        "ä¼½é©¬å¤šæ™®å‹’", # Gamma Doppler
        "è™ç‰™",      # Tiger Tooth
        "é»‘è‰²å±‚å‹æ¿", # Black Laminate
        "å± å¤«",      # Slaughter
        "ä¼ è¯´",      # Legend
    ],
    "åˆºåˆ€": [
        "æ¸å˜ä¹‹è‰²",  # Fade
        "å¤šæ™®å‹’",    # Doppler
        "ä¼½é©¬å¤šæ™®å‹’", # Gamma Doppler
        "è™ç‰™",      # Tiger Tooth
        "é»‘è‰²å±‚å‹æ¿", # Black Laminate
        "å± å¤«",      # Slaughter
        "ä¼ è¯´",      # Legend
    ],
    "é²ä¼ŠçŒåˆ€": [
        "å± å¤«",      # Slaughter
    ],
    "å¼¯åˆ€": [
        "å± å¤«",      # Slaughter
    ],
    "æŠ˜å åˆ€": [
        "æ¸å˜ä¹‹è‰²",  # Fade
        "å¤šæ™®å‹’",    # Doppler
        "ä¼½é©¬å¤šæ™®å‹’", # Gamma Doppler
        "è™ç‰™",      # Tiger Tooth
        "é»‘è‰²å±‚å‹æ¿", # Black Laminate
        "å± å¤«",      # Slaughter
        "ä¼ è¯´",      # Legend
    ],
    "ç©¿è‚ åˆ€": [
        "å± å¤«",      # Slaughter
    ],
    "çŒæ€è€…åŒ•é¦–": [
        "å± å¤«",      # Slaughter
    ],
    "çˆªå­åˆ€": [
        "æ¸å˜ä¹‹è‰²",  # Fade
        "å¤šæ™®å‹’",    # Doppler
        "ä¼½é©¬å¤šæ™®å‹’", # Gamma Doppler
        "è™ç‰™",      # Tiger Tooth
        "é»‘è‰²å±‚å‹æ¿", # Black Laminate
        "å± å¤«",      # Slaughter
        "ä¼ è¯´",      # Legend
    ],
    "æš—å½±åŒåŒ•": [
        "å± å¤«",      # Slaughter
    ],
    "çŸ­å‰‘": [
        "å¤šæ™®å‹’",    # Doppler
        "è™ç‰™",      # Tiger Tooth
        "å± å¤«",      # Slaughter
    ],
    "ç†Šåˆ€": [
        "å± å¤«",      # Slaughter
    ],
    "æŠ˜åˆ€": [
        "å± å¤«",      # Slaughter
    ],
    "é”¯é½¿çˆªåˆ€": [
        "æ¸å˜ä¹‹è‰²",  # Fade
        "å¤šæ™®å‹’",    # Doppler
        "è™ç‰™",      # Tiger Tooth
        "å± å¤«",      # Slaughter
    ],
    "æµ·è±¹çŸ­åˆ€": [
        "å± å¤«",      # Slaughter
    ],
    "ç³»ç»³åŒ•é¦–": [
        "æ¸å˜ä¹‹è‰²",  # Fade
        "å¤šæ™®å‹’",    # Doppler
        "è™ç‰™",      # Tiger Tooth
        "å± å¤«",      # Slaughter
    ],
    "æ±‚ç”ŸåŒ•é¦–": [
        "æ¸å˜ä¹‹è‰²",  # Fade
        "å¤šæ™®å‹’",    # Doppler
        "è™ç‰™",      # Tiger Tooth
        "å± å¤«",      # Slaughter
    ],
    "æµæµªè€…åŒ•é¦–": [
        "æ¸å˜ä¹‹è‰²",  # Fade
        "å¤šæ™®å‹’",    # Doppler
        "è™ç‰™",      # Tiger Tooth
        "å± å¤«",      # Slaughter
    ],
    "éª·é«…åŒ•é¦–": [
        "æ¸å˜ä¹‹è‰²",  # Fade
        "å¤šæ™®å‹’",    # Doppler
        "è™ç‰™",      # Tiger Tooth
        "å± å¤«",      # Slaughter
    ],
    "å»“å°”å–€åˆ€": [
        "å± å¤«",      # Slaughter
    ],
}

# æ–°å¢ç±»åˆ«çš„æ¨¡ç‰ˆé…ç½®
ITEM_TEMPLATES = {
    # æ¢å‘˜æ¨¡ç‰ˆé…ç½®
    "æ¢å‘˜": [
            "æ®‹é…·çš„è¾¾é‡Œå°”çˆµå£«ï¼ˆè¿ˆé˜¿å¯†ï¼‰", "æŒ‡æŒ¥å®˜é»›ç»´è¾¾Â·è´¹å°”å—å¾·æ–¯ï¼ˆæŠ¤ç›®é•œï¼‰", "å‡ºé€ƒçš„è¨è‰",
            "æŒ‡æŒ¥å®˜å¼—å…°å…‹Â·å·´é²å¾·ï¼ˆæ¹¿è¢œï¼‰", "è€ K", "æ®‹é…·çš„è¾¾é‡Œå°”çˆµå£«ï¼ˆè’å™ªï¼‰",
            "æ®‹é…·çš„è¾¾é‡Œå°”çˆµå£«ï¼ˆçš‡å®¶ï¼‰", "è–‡å¸•å§ï¼ˆé©æ–°æ´¾ï¼‰", "D ä¸­é˜Ÿå†›å®˜",
            "æ®‹é…·çš„è¾¾é‡Œå°”çˆµå£«ï¼ˆå¤´ç›–éª¨ï¼‰", "é™†å†›ä¸­å°‰æ™®é‡Œç±³ç½—", "æ®‹é…·çš„è¾¾é‡Œå°”ï¼ˆç©·é¬¼ï¼‰",
            "æ®‹é…·çš„è¾¾é‡Œå°”çˆµå£«ï¼ˆæ²‰é»˜ï¼‰", "å°å‡¯å¤«", "ä¸Šæ ¡æ›¼æˆˆæ–¯Â·è¾¾æ¯”è¥¿",
            "å…‹æ‹‰æ–¯æ²ƒç‰¹ï¼ˆä¸‰åˆ†ç†Ÿï¼‰", "ç²¾é”æ•å…½è€…ç´¢å°”æ›¼", "çˆ±å¨ƒç‰¹å·¥",
            "ä¸­é˜Ÿé•¿é²æ²™å°”Â·å‹’åº“æ‰˜", "åŒ–å­¦é˜²å®³ä¸Šå°‰", "æ•å…½è€…", "é£è´¼æ³¢å…¹æ›¼",
            '"è“è“" é“…å¼¹', "é—å¿˜è€…å…‹æ‹‰æ–¯æ²ƒç‰¹", "ä¸›æ—åæŠ—è€…", "æµ·å†›ä¸Šå°‰é‡Œå…‹ç´¢å°”",
            "æ•å…½è€…ï¼ˆæŒ‘è¡…è€…ï¼‰", "å†›å®˜é›…å…‹Â·è´å°”ç‰¹æœ—", 'æŒ‡æŒ¥å®˜ æ¢… "æå¯’" è´¾ç±³æ£®',
            "ä¸­å°‰æ³•æ´›ï¼ˆæŠ±æ ‘äººï¼‰", "å¾·å›½ç‰¹ç§éƒ¨é˜Ÿçªå‡»é˜Ÿ", "ä¸­å°‰é›·å…‹æ–¯Â·å…‹é‡Œå¥‡",
            "åŒ–å­¦é˜²å®³ä¸“å®¶", '"åŒ»ç”Ÿ" ç½—æ›¼è¯ºå¤«', "ç”Ÿç‰©é˜²å®³ä¸“å®¶",
            "æµ·è±¹çªå‡»é˜Ÿç¬¬å…­åˆ†é˜Ÿå£«å…µ", "äºšè¯ºï¼ˆé‡è‰ï¼‰", "è¡—å¤´å£«å…µ", "å†›å£«é•¿ç‚¸å¼¹æ£®",
            'çº¦ç¿° "èŒƒÂ·æµ·ä¼¦" å¡æ–¯å…‹', "ç¬¬ä¸€ä¸­å°‰æ³•æ´›", "è”é‚¦è°ƒæŸ¥å±€ï¼ˆFBIï¼‰ç‰¹è­¦", "ç²¾è‹±ç©†å“ˆé‡Œå…‹å…ˆç”Ÿ",
            "å†›åŒ»å°‘å°‰", "B ä¸­é˜ŸæŒ‡æŒ¥å®˜", "å‡†å°‰", "è¿ˆå…‹Â·èµ›å¼—æ–¯", "é»‘ç‹¼",
            '"ä¸¤æ¬¡" éº¦è€ƒä¼Š', "çº¢è¡«åˆ—èµ", "å¾·æ‹‰æˆˆç±³å°”", "å‡†å¤‡å°±ç»ªçš„åˆ—èµ",
            "é“…å¼¹", "é©¬å°”åº“æ–¯Â·æˆ´åŠ³", "å‡¤å‡°æˆ˜å£«", "å¥¥è¥¿ç‘æ–¯", "é©¬å…‹è¥¿å§†æ–¯",
            "æ²™å“ˆé©¬ç‰¹æ•™æˆ", "åœ°é¢å›å†›"
    ],
    
    # æ‰‹æªæ¨¡ç‰ˆé…ç½®
    "USP æ¶ˆéŸ³ç‰ˆ": [
        "é“¶è£…ç´ è£¹",
        "é”å®š",
        "çŒæˆ·",
        "é»‘æ°´",
        "è¡€åˆƒ",
        "é»‘è‰²é­…å½±",
        "å°èŠ±é›†", # Printstream
        "å€’åŠäºº", # Hanged Man
        "æ¬¡æ—¶ä»£", # Next Generation
        "æªå“äººäº¡", # Gunsmoke
        "è„‘æ´å¤§å¼€", # Mind the Gap
        "ç ´é„‚è€…", # Jawbreaker
    ],
    "æ ¼æ´›å…‹ 18 å‹": [
        "å¿ç³", # Ninjas in Pyjamas
        "ä¼½é©¬å¤šæ™®å‹’", # Gamma Doppler
        "å­å¼¹çš‡å", # Bullet Queen
        "æ°´çµ", # Water Elemental
        "æ‘©ç™»æ—¶ä»£", # Modern Warfare
        "å¤§é‡‘ç‰™", # Big Badger
        "é»‘è‰²é­…å½±", # Black Laminate
        "é›¶é£Ÿæ´¾å¯¹", # Snack Attack
        "æ¸å˜ä¹‹è‰²", # Fade
        "AXIA",
        "è’é‡åå›",
        
    ],
    "æ²™æ¼ ä¹‹é¹°": [
        "ç‚½çƒˆä¹‹ç‚", # Blaze
        "ç¿¡ç¿ å·¨èŸ’", # Emerald Python
        "æ²™æ¼ ä¹‹ç‹", # Desert Fox
        "å°èŠ±é›†", # Printstream
        "æ³¢æ¶›çºµæ¨ª", # Ripple
        "æ˜Ÿè¾°æ‹±å»Š", # Starlight Guard
        "é’´è“ç¦é”¢", # Cobalt Obliteration
        "çº¢è‰²ä»£å·", # Redline
        "é©¬ç€ä¸½", # Marple
    ],
    
    # æ­¥æªæ¨¡ç‰ˆé…ç½®
    "AK-47": [
        "é‡è·",
        "æ°´æ ½ç«¹",
        "é»„é‡‘è—¤è”“",
        "ç«è›‡",
        "ç«ç¥",
        "æ€ªå…½åœ¨B",
        "ç‡ƒæ–™å–·å°„å™¨",
        "çº¢çº¿",
        "è¡€è…¥è¿åŠ¨",
        "æ–°çº¢æµªæ½®",
        "ä¼ æ‰¿",
        "æŠ½è±¡æ´¾ 1337",
        "è’é‡åå›",
        "çš‡å",
        "äºŒè¥¿è«å¤«",
        "Xå°„çº¿",
        "æ·±æµ·å¤ä»‡",
        "å¡ç‰¹å°”",
        "æ··æ²Œç‚¹é˜µ",
        "ç¾æ´²çŒ›è™",
        "ç¾æ´²è±¹",
        "éœ“è™¹éª‘å£«",
        "å¤œæ„¿",
        "è½¨é“ Mk01",
        "ä¸€å‘å…¥é­‚",
        "å±€å¤–äºº",
        
    ],
    "M4A1": [
        "èµ¤çº¢æ–°æ˜Ÿ",
        "å†’é™©å®¶ä¹å›­",
        "ç´§è¿«å±æœº",
        "æ¾œç£·",
        "æ¸å˜ä¹‹è‰²",
        "ä¼Šå¡æ´›æ–¯çš„é™¨è½",
        "å°èŠ±é›†",
        "è’¸æ±½æ³¢",
        "äºŒå·ç©å®¶",
        "æ¬¡æ—¶ä»£",
        "åŸå­åˆé‡‘",
        "å¥³ç«ç¥ä¹‹ç‚½ç„°",
        "æ¢¦é­‡",
        
    ],
    "M4A4": [
        "ç ´æ™“",
        "è·é²æ–¯ä¹‹çœ¼",
        "åˆçºµ",
        "äºŒè¥¿è«å¤«",
        "å–§åš£æ€æˆ®",
        "ç‚¼ç‹±ä¹‹ç«",
        "åœ°ç‹±çƒˆç„°",
        "çš‡å¸",
        "çš‡å®¶åœ£éª‘å£«",
        "åå†²ç²¾è‹±",
        "é»‘è‰²é­…å½±",
        "æ´»è‰²ç”Ÿé¦™",
    ],
    "AWP": [
        "ä¹å¤´é‡‘è›‡",
        "é›·å‡»",
        "é¬¼é€€æ²»",
        "äºŒè¥¿è«å¤«",
        "çº¢çº¿",
        "å°èŠ±é›†",
        "é•€é“¬å¤§ç‚®",
        "é»‘è‰²é­…å½±",
    ],
    
    # æ‰‹å¥—æ¨¡ç‰ˆé…ç½®
    "è¿åŠ¨æ‰‹å¥—": [
        "æ ‘ç¯±è¿·å®«",
        "æ½˜å¤šæ‹‰ä¹‹ç›’",
        "è¶…å¯¼ä½“",
        "è¿ˆé˜¿å¯†é£äº‘",
        "å¹²æ—±",
        "å¼¹å¼“",
        "å¤œè¡Œè¡£",
        "åŒæ –",
        "æ¬§ç±³ä¼½",
    ],
    "ä¸“ä¸šæ‰‹å¥—": [
        "æ·±çº¢å’Œæœ",
        "ç¿ ç»¿ä¹‹ç½‘",
        "å…ƒå‹‹",
        "æ¸å˜ä¹‹è‰²",
        "è€è™ç²¾è‹±",
    ],
    "æ‘©æ‰˜æ‰‹å¥—": [
        "è–„è·",
        "æ¸…å‡‰è–„è·",
        "*å˜£ï¼*",
        "*å˜­ï¼*",
    ],
}



# APIåˆè§„é…ç½®
REQUEST_INTERVAL = 0.5  # ä¸¥æ ¼1ç§’é—´éš”
MAX_RETRIES = 5  # æœ€å¤§é‡è¯•æ¬¡æ•°
RATE_LIMIT_DELAY = 5  # é‡åˆ°é™æµæ—¶çš„å»¶è¿Ÿ

# å¤šçº¿ç¨‹é…ç½®
DEFAULT_MAX_WORKERS = 4  # é»˜è®¤å¤„ç†çº¿ç¨‹æ•°

# å¹³å°é…ç½®
PLATFORM_MAP = {1: "BUFF", 2: "YYYP"}
DEFAULT_PLATFORMS = [1, 2]  # åªä½¿ç”¨BUFFå’ŒYYYP

# æ•°æ®è·å–é…ç½®
MIN_PRICE_THRESHOLD = 100  # æœ€ä½ä»·æ ¼é˜ˆå€¼

class ItemDatabaseBuilder:
    def __init__(self, api_token: str, use_multithreading: bool = False, max_workers: int = DEFAULT_MAX_WORKERS, enable_template_filter: bool = True):
        self.client = CsqaqClient(api_token=api_token)
        self.api_token = api_token
        self.use_multithreading = use_multithreading
        self.max_workers = max_workers
        self.enable_template_filter = enable_template_filter
        
        # è·å–åŒ—äº¬æ—¶é—´
        self.current_time = self.get_beijing_time()
        
        # è®¾ç½®ç¼“å­˜å’Œæ•°æ®é›†ç›®å½•ï¼Œéƒ½åœ¨Modelç›®å½•ä¸‹
        base_dir = os.path.dirname(__file__)
        self.cache_dir = os.path.join(base_dir, "cache")
        self.dataset_dir = os.path.join(base_dir, "dataset")
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        if not os.path.exists(self.cache_dir):
            os.makedirs(self.cache_dir)
        if not os.path.exists(self.dataset_dir):
            os.makedirs(self.dataset_dir)
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_requests': 0,
            'successful_requests': 0,
            'failed_requests': 0,
            'rate_limit_hits': 0,
            'start_time': time.time(),
            'last_request_time': 0
        }
        
        # å¤šçº¿ç¨‹ç›¸å…³
        if self.use_multithreading:
            self.lock = threading.Lock()
            self.file_locks = {}  # æ–‡ä»¶å†™å…¥é”
    
    def get_beijing_time(self) -> str:
        """è·å–åŒ—äº¬æ—¶é—´"""
        # è·å–UTCæ—¶é—´
        utc_now = datetime.now(timezone.utc)
        # åŒ—äº¬æ—¶é—´æ˜¯UTC+8
        beijing_tz = timezone(timedelta(hours=8))
        beijing_time = utc_now.astimezone(beijing_tz)
        return beijing_time.strftime("%Y-%m-%d %H:%M")
    
    def enforce_rate_limit(self):
        """å¼ºåˆ¶æ‰§è¡ŒAPIé¢‘ç‡é™åˆ¶"""
        if self.use_multithreading:
            with self.lock:
                current_time = time.time()
                time_since_last = current_time - self.stats['last_request_time']
                
                if time_since_last < REQUEST_INTERVAL:
                    sleep_time = REQUEST_INTERVAL - time_since_last
                    print(f"    â³ ç­‰å¾… {sleep_time:.1f} ç§’ä»¥ç¬¦åˆAPIé™åˆ¶...")
                    time.sleep(sleep_time)
                
                self.stats['last_request_time'] = time.time()
        else:
            current_time = time.time()
            time_since_last = current_time - self.stats['last_request_time']
            
            if time_since_last < REQUEST_INTERVAL:
                sleep_time = REQUEST_INTERVAL - time_since_last
                print(f"    â³ ç­‰å¾… {sleep_time:.1f} ç§’ä»¥ç¬¦åˆAPIé™åˆ¶...")
                time.sleep(sleep_time)
            
            self.stats['last_request_time'] = time.time()
        
    def ensure_dir(self, path: str):
        """ç¡®ä¿ç›®å½•å­˜åœ¨"""
        os.makedirs(path, exist_ok=True)
    
    def get_cache_file_path(self, item_type: str) -> str:
        """è·å–ç¼“å­˜æ–‡ä»¶è·¯å¾„"""
        # è·å–ç‰©å“ç±»å‹æ‰€å±çš„ç±»åˆ«
        category = self.get_category_for_item_type(item_type)
        
        # ç¼“å­˜æ–‡ä»¶è·¯å¾„ï¼šcache/ç±»åˆ«/ç‰©å“ç±»å‹_items_cache.json
        return os.path.join(self.cache_dir, category, f"{item_type}_items_cache.json")
    
    def load_cached_items(self, item_type: str) -> Dict[str, Any]:
        """åŠ è½½ç¼“å­˜çš„å•†å“ä¿¡æ¯"""
        cache_file = self.get_cache_file_path(item_type)
        if os.path.exists(cache_file):
            try:
                with open(cache_file, 'r', encoding='utf-8') as f:
                    cache_data = json.load(f)
                    print(f"âœ… ä»ç¼“å­˜åŠ è½½ {len(cache_data.get('items', {}))} ä¸ª {item_type} å•†å“")
                    return cache_data
            except Exception as e:
                print(f"âŒ åŠ è½½ç¼“å­˜å¤±è´¥ï¼š{e}")
        return {}
    
    def save_cached_items(self, item_type: str, items_info: Dict[str, Any]):
        """ä¿å­˜å•†å“ä¿¡æ¯åˆ°ç¼“å­˜"""
        cache_file = self.get_cache_file_path(item_type)
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        cache_dir = os.path.dirname(cache_file)
        os.makedirs(cache_dir, exist_ok=True)
        
        cache_data = {
            "item_type": item_type,
            "category": self.get_category_for_item_type(item_type),
            "update_time": self.current_time,
            "items": items_info
        }
        try:
            with open(cache_file, 'w', encoding='utf-8') as f:
                json.dump(cache_data, f, ensure_ascii=False, indent=2)
            print(f"âœ… ç¼“å­˜ {len(items_info)} ä¸ª {item_type} å•†å“ä¿¡æ¯")
        except Exception as e:
            print(f"âŒ ä¿å­˜ç¼“å­˜å¤±è´¥ï¼š{e}")
    
    def should_filter_item(self, item_name: str, item_type: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥è¿‡æ»¤æ‰æŸä¸ªç‰©å“"""
        item_name_lower = item_name.lower()
        
        # 1. è¿‡æ»¤æ‰åŒ…å«åŸºç¡€è¿‡æ»¤å…³é”®è¯çš„ç‰©å“ï¼ˆç²¾ç¡®åŒ¹é…ï¼Œé¿å…è¯¯è¿‡æ»¤ï¼‰
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ç‹¬ç«‹çš„è¿‡æ»¤å…³é”®è¯ï¼Œè€Œä¸æ˜¯ä½œä¸ºå…¶ä»–è¯çš„ä¸€éƒ¨åˆ†
        for keyword in FILTER_KEYWORDS:
            # ä½¿ç”¨æ›´ç²¾ç¡®çš„åŒ¹é…ï¼Œé¿å…è¯¯è¿‡æ»¤åŒ…å«è¿™äº›å…³é”®è¯çš„æ­£å¸¸çš®è‚¤åç§°
            if keyword in item_name:
                # æ£€æŸ¥æ˜¯å¦æ˜¯ç‹¬ç«‹çš„è¿‡æ»¤å…³é”®è¯ï¼Œè€Œä¸æ˜¯çš®è‚¤åç§°çš„ä¸€éƒ¨åˆ†
                if keyword == "å°èŠ±" and "å°èŠ±é›†" in item_name:
                    # "å°èŠ±é›†"æ˜¯æ­£å¸¸çš®è‚¤åç§°ï¼Œä¸åº”è¯¥è¢«è¿‡æ»¤
                    continue
                if keyword == "æŒ‚ä»¶" and ("æŒ‚ä»¶" in item_name and len(item_name.split("æŒ‚ä»¶")) > 2):
                    # å¦‚æœ"æŒ‚ä»¶"å‡ºç°åœ¨å¤šä¸ªåœ°æ–¹ï¼Œå¯èƒ½æ˜¯æ­£å¸¸çš®è‚¤åç§°çš„ä¸€éƒ¨åˆ†
                    continue
                return True
        
        # 2. è¿‡æ»¤æ‰StatTrakç‰©å“ï¼ˆä»…åœ¨æŒ‡å®šç±»åˆ«ä¸­ï¼‰
        category = self.get_category_for_item_type(item_type)
        if category in STATTRAK_FILTER_CATEGORIES:
            if "stattrak" in item_name_lower or "stat trak" in item_name_lower:
                return True
        
        # 3. è¿‡æ»¤æ‰ç‰¹å®šå¤–è§‚å“è´¨çš„ç‰©å“ï¼ˆåœ¨æŒ‡å®šç±»åˆ«ä¸­ï¼‰
        exterior_filter_categories = ["åŒ•é¦–", "æ‰‹æª", "æ­¥æª", "æ‰‹å¥—"]
        if category in exterior_filter_categories:
            for keyword in EXTERIOR_FILTER_KEYWORDS:
                if keyword in item_name:
                    return True
        
        return False
    
    def search_and_cache_items(self, item_type: str, keywords: List[str]) -> Dict[str, Any]:
        """æœç´¢å¹¶ç¼“å­˜å•†å“ä¿¡æ¯ï¼ˆAPIåˆè§„ç‰ˆæœ¬ï¼‰"""
        print(f"ğŸ” æœç´¢ {item_type} å•†å“ï¼ˆAPIåˆè§„æ¨¡å¼ï¼‰...")
        
        all_items_info = {}
        filtered_count = 0
        
        # ä½¿ç”¨å¤šä¸ªå…³é”®è¯æœç´¢
        for keyword in keywords:
            print(f"  æœç´¢å…³é”®è¯ï¼š{keyword}")
            
            # åˆ†é¡µè·å–æ‰€æœ‰å•†å“
            page_index = 1
            while True:
                try:
                    # å¼ºåˆ¶æ‰§è¡Œé¢‘ç‡é™åˆ¶
                    self.enforce_rate_limit()
                    
                    response = self.client.get_good_id(page_index=page_index, page_size=50, search=keyword)
                    data = response.get("data", {})
                    
                    # APIè¿”å›çš„æ•°æ®ç»“æ„æ˜¯ data.dataï¼ŒåŒ…å«å•†å“å­—å…¸
                    goods_dict = data.get("data", {})
                    
                    if not goods_dict:
                        break
                    
                    # æå–å•†å“ä¿¡æ¯
                    for good_id, item in goods_dict.items():
                        if good_id:
                            item_name = item.get("name", "")
                            
                            # ä½¿ç”¨æ–°çš„è¿‡æ»¤å‡½æ•°
                            if self.should_filter_item(item_name, item_type):
                                filtered_count += 1
                                continue
                                
                            all_items_info[str(good_id)] = {
                                "good_id": str(good_id),
                                "name": item_name,
                                "market_hash_name": item.get("market_hash_name", ""),
                                "keyword": keyword
                            }
                    
                    page_index += 1
                    
                    # é™åˆ¶æœç´¢é¡µæ•°ï¼Œé¿å…è¿‡å¤šè¯·æ±‚
                    if page_index > 5:
                        break
                        
                except Exception as e:
                    print(f"  è·å–ç¬¬{page_index}é¡µå¤±è´¥ï¼š{e}")
                    break
        
        print(f"  æ€»å…±æ‰¾åˆ° {len(all_items_info)} ä¸ª {item_type} ç›¸å…³å•†å“")
        if filtered_count > 0:
            print(f"  è¿‡æ»¤æ‰ {filtered_count} ä¸ªä¸ç¬¦åˆæ¡ä»¶çš„å•†å“")
        
        # ä¿å­˜åˆ°ç¼“å­˜
        self.save_cached_items(item_type, all_items_info)
        
        return all_items_info
    
    def safe_get(self, d: Dict, *ks, default=None):
        """å®‰å…¨è·å–åµŒå¥—å­—å…¸å€¼"""
        cur = d
        for k in ks:
            if isinstance(cur, dict) and k in cur:
                cur = cur[k]
            else:
                return default
        return cur
    
    def get_single_good_detail(self, good_id: str) -> Dict[str, Any]:
        """è·å–å•ä¸ªå•†å“è¯¦æƒ…ï¼ˆä¸¥æ ¼éµå¾ªAPIé™åˆ¶ï¼‰"""
        for attempt in range(MAX_RETRIES):
            try:
                # å¼ºåˆ¶æ‰§è¡Œé¢‘ç‡é™åˆ¶
                self.enforce_rate_limit()
                
                print(f"    ğŸ“¡ è·å–å•†å“ {good_id} è¯¦æƒ…... (å°è¯• {attempt + 1}/{MAX_RETRIES})")
                detail = self.client.good_detail(good_id)
                
                if self.use_multithreading:
                    with self.lock:
                        self.stats['successful_requests'] += 1
                else:
                    self.stats['successful_requests'] += 1
                    
                print(f"    âœ… å•†å“ {good_id} è·å–æˆåŠŸ")
                return detail
                
            except Exception as e:
                error_str = str(e).lower()
                
                if self.use_multithreading:
                    with self.lock:
                        self.stats['failed_requests'] += 1
                else:
                    self.stats['failed_requests'] += 1
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºé™æµé”™è¯¯
                if '429' in error_str or 'rate limit' in error_str or 'too many requests' in error_str:
                    if self.use_multithreading:
                        with self.lock:
                            self.stats['rate_limit_hits'] += 1
                    else:
                        self.stats['rate_limit_hits'] += 1
                        
                    print(f"    âš ï¸ å•†å“ {good_id} é‡åˆ°é™æµï¼Œç­‰å¾… {RATE_LIMIT_DELAY} ç§’...")
                    time.sleep(RATE_LIMIT_DELAY)
                else:
                    # å…¶ä»–é”™è¯¯ï¼Œä½¿ç”¨æŒ‡æ•°é€€é¿
                    wait_time = min(2 ** attempt, 10)  # æœ€å¤§ç­‰å¾…10ç§’
                    print(f"    âš ï¸ å•†å“ {good_id} è¯·æ±‚å¤±è´¥ï¼š{e}")
                    print(f"    â³ ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    time.sleep(wait_time)
                
                if attempt == MAX_RETRIES - 1:
                    print(f"    âŒ å•†å“ {good_id} é‡è¯• {MAX_RETRIES} æ¬¡åä»ç„¶å¤±è´¥")
                    return None
        
        return None
    
    def get_all_good_details(self, good_ids: List[str]) -> Dict[str, Any]:
        """è·å–æ‰€æœ‰å•†å“è¯¦æƒ…ï¼ˆä¸²è¡Œå¤„ç†ï¼Œä¸¥æ ¼éµå¾ªAPIé™åˆ¶ï¼‰"""
        print(f"ğŸ“¡ å¼€å§‹è·å– {len(good_ids)} ä¸ªå•†å“è¯¦æƒ…ï¼ˆAPIåˆè§„æ¨¡å¼ï¼‰...")
        print(f"âš™ï¸ é…ç½®ï¼šä¸¥æ ¼1ç§’é—´éš”ï¼Œæ— å¹¶å‘è¯·æ±‚")
        
        results = {}
        start_time = time.time()
        
        for i, good_id in enumerate(good_ids):
            print(f"\nğŸ“Š è¿›åº¦ï¼š{i+1}/{len(good_ids)} ({((i+1)/len(good_ids)*100):.1f}%)")
            
            detail = self.get_single_good_detail(good_id)
            if detail:
                results[good_id] = detail
            
            self.stats['total_requests'] += 1
            
            # æ˜¾ç¤ºé¢„ä¼°å‰©ä½™æ—¶é—´
            if i > 0:
                elapsed_time = time.time() - start_time
                avg_time_per_request = elapsed_time / (i + 1)
                remaining_requests = len(good_ids) - (i + 1)
                estimated_remaining_time = remaining_requests * avg_time_per_request
                
                print(f"    â±ï¸  å·²è€—æ—¶ï¼š{elapsed_time:.1f}ç§’")
                print(f"    ğŸ“ˆ å¹³å‡æ¯è¯·æ±‚ï¼š{avg_time_per_request:.1f}ç§’")
                print(f"    â° é¢„ä¼°å‰©ä½™ï¼š{estimated_remaining_time:.1f}ç§’")
        
        end_time = time.time()
        total_time = end_time - start_time
        
        print(f"\nâœ… å•†å“è¯¦æƒ…è·å–å®Œæˆ")
        print(f"  - æˆåŠŸè·å–ï¼š{len(results)}/{len(good_ids)} ä¸ªå•†å“")
        print(f"  - æˆåŠŸç‡ï¼š{len(results)/len(good_ids)*100:.1f}%")
        print(f"  - æ€»è€—æ—¶ï¼š{total_time:.1f}ç§’")
        print(f"  - å¹³å‡è€—æ—¶ï¼š{total_time/len(good_ids):.1f}ç§’/å•†å“")
        print(f"  - é™æµæ¬¡æ•°ï¼š{self.stats['rate_limit_hits']}")
        
        return results
    
    def get_vol_data_info(self) -> Dict[str, int]:
        """è·å–æˆäº¤é‡æ•°æ®ä¿¡æ¯"""
        print("ğŸ“Š è·å–æˆäº¤é‡æ•°æ®...")
        self.enforce_rate_limit()
        
        try:
            url = "https://api.csqaq.com/api/v1/info/vol_data_info"
            headers = {
                'ApiToken': self.api_token,
                'Content-Type': 'application/json'
            }
            
            import requests
            response = requests.post(url, headers=headers, json={}, timeout=30)
            
            if response.status_code == 200:
                data = response.json()
                if 'data' in data and isinstance(data['data'], list):
                    vol_data = {}
                    for item in data['data']:
                        good_id = str(item.get('good_id', ''))
                        statistic = item.get('statistic', 0)
                        vol_data[good_id] = statistic
                    
                    print(f"âœ… æˆåŠŸè·å– {len(vol_data)} ä¸ªç‰©å“çš„æˆäº¤é‡æ•°æ®")
                    return vol_data
                else:
                    print("âŒ æˆäº¤é‡æ•°æ®æ ¼å¼é”™è¯¯")
                    return {}
            else:
                print(f"âŒ è·å–æˆäº¤é‡æ•°æ®å¤±è´¥: {response.status_code}")
                return {}
                
        except Exception as e:
            print(f"âŒ è·å–æˆäº¤é‡æ•°æ®å¼‚å¸¸: {e}")
            return {}
    
    def get_item_template(self, item_name: str) -> str:
        """ä»å•†å“åç§°ä¸­è¯†åˆ«æ¨¡ç‰ˆç±»å‹"""
        item_name_lower = item_name.lower()
        
        # ç‰¹æ®Šå¤„ç†æ¢å‘˜ï¼šæ¢å‘˜æ˜¯å…·ä½“çš„ç‰©å“åç§°ï¼Œç›´æ¥è¿”å›ç‰©å“åç§°
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ¢å‘˜ç›¸å…³å…³é”®è¯
        if any(keyword in item_name_lower for keyword in ["agent", "æ¢å‘˜", "t agent", "ct agent"]):
            # å¯¹äºæ¢å‘˜ï¼Œç›´æ¥è¿”å›ç‰©å“åç§°ä½œä¸ºæ¨¡æ¿
            return item_name
        
        # å¯¹äºå…¶ä»–ç‰©å“ç±»å‹ï¼Œç›´æ¥è¿”å›ç‰©å“åç§°ä½œä¸ºæ¨¡æ¿
        # å› ä¸ºæˆ‘ä»¬å·²ç»æœ‰äº†è¯¦ç»†çš„æ¨¡æ¿é…ç½®ï¼Œä¸éœ€è¦å…³é”®è¯æ˜ å°„
        return item_name
    
    def filter_items_by_templates(self, item_type: str, all_items_info: Dict[str, Any], verbose: bool = True) -> Dict[str, Any]:
        """æ ¹æ®æ¨¡ç‰ˆé…ç½®ç­›é€‰å•†å“"""
        if not self.enable_template_filter:
            if verbose:
                print(f"ğŸ“ æ¨¡ç‰ˆç­›é€‰å·²ç¦ç”¨ï¼Œä¿ç•™æ‰€æœ‰å•†å“")
            return all_items_info
        
        # æ£€æŸ¥æ˜¯å¦åœ¨åŒ•é¦–æ¨¡ç‰ˆé…ç½®ä¸­
        if item_type in KNIFE_TEMPLATES:
            target_templates = KNIFE_TEMPLATES[item_type]
            if verbose:
                print(f"ğŸ¯ {item_type} åŒ•é¦–æ¨¡ç‰ˆç­›é€‰ï¼š{', '.join(target_templates)}")
        # æ£€æŸ¥æ˜¯å¦åœ¨ç‰©å“æ¨¡ç‰ˆé…ç½®ä¸­
        elif item_type in ITEM_TEMPLATES:
            target_templates = ITEM_TEMPLATES[item_type]
            if verbose:
                print(f"ğŸ¯ {item_type} ç‰©å“æ¨¡ç‰ˆç­›é€‰ï¼š{', '.join(target_templates)}")
        else:
            if verbose:
                print(f"ğŸ“ {item_type} æœªé…ç½®æ¨¡ç‰ˆç­›é€‰ï¼Œä¿ç•™æ‰€æœ‰å•†å“")
            return all_items_info
        
        filtered_items = {}
        template_stats = {}
        
        for good_id, item_info in all_items_info.items():
            item_name = item_info.get("name", "")
            
            # é¦–å…ˆåº”ç”¨è¿‡æ»¤é€»è¾‘ï¼Œè¿‡æ»¤æ‰ä¸åº”è¯¥çš„å•†å“
            if self.should_filter_item(item_name, item_type):
                continue
            
            # ç‰¹æ®Šå¤„ç†æ¢å‘˜ç±»åˆ«ï¼šä½¿ç”¨åŒ…å«åŒ¹é…è€Œä¸æ˜¯ç²¾ç¡®åŒ¹é…
            if item_type == "æ¢å‘˜":
                matched = False
                for target_template in target_templates:
                    if target_template in item_name:
                        filtered_items[good_id] = item_info
                        template_stats[target_template] = template_stats.get(target_template, 0) + 1
                        matched = True
                        break
            else:
                # å…¶ä»–ç±»åˆ«ï¼šåœ¨ç‰©å“åç§°ä¸­æœç´¢æ¨¡æ¿å…³é”®è¯
                matched = False
                for target_template in target_templates:
                    if target_template.lower() in item_name.lower():
                        filtered_items[good_id] = item_info
                        template_stats[target_template] = template_stats.get(target_template, 0) + 1
                        matched = True
                        break
        
        if verbose:
            print(f"âœ… æ¨¡ç‰ˆç­›é€‰ç»“æœï¼š")
            print(f"  - åŸå§‹å•†å“æ•°é‡ï¼š{len(all_items_info)}")
            print(f"  - ç­›é€‰åæ•°é‡ï¼š{len(filtered_items)}")
            print(f"  - ç­›é€‰ç‡ï¼š{len(filtered_items)/len(all_items_info)*100:.1f}%")
            
            for template, count in template_stats.items():
                print(f"  - {template}ï¼š{count} ä¸ª")
        
        return filtered_items
    
    def is_doppler_item(self, item_name: str) -> Tuple[bool, str, str]:
        """åˆ¤æ–­æ˜¯å¦ä¸ºå¤šæ™®å‹’ç³»åˆ—ç‰©å“ï¼Œè¿”å›(æ˜¯å¦æ˜¯å¤šæ™®å‹’, å¤šæ™®å‹’ç±»å‹, å…·ä½“Phase)"""
        item_name_lower = item_name.lower()
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºå¤šæ™®å‹’
        if "doppler" in item_name_lower:
            # æ£€æŸ¥æ˜¯å¦ä¸ºä¼½é©¬å¤šæ™®å‹’
            if "gamma" in item_name_lower:
                doppler_type = "ä¼½é©¬å¤šæ™®å‹’"
            else:
                doppler_type = "å¤šæ™®å‹’"
            
            # æ£€æŸ¥å…·ä½“Phase
            if "ruby" in item_name_lower or "çº¢å®çŸ³" in item_name_lower:
                return True, doppler_type, "çº¢å®çŸ³"
            elif "sapphire" in item_name_lower or "è“å®çŸ³" in item_name_lower:
                return True, doppler_type, "è“å®çŸ³"
            elif "emerald" in item_name_lower or "ç»¿å®çŸ³" in item_name_lower:
                return True, doppler_type, "ç»¿å®çŸ³"
            elif "phase 1" in item_name_lower or "p1" in item_name_lower:
                return True, doppler_type, "Phase1"
            elif "phase 2" in item_name_lower or "p2" in item_name_lower:
                return True, doppler_type, "Phase2"
            elif "phase 3" in item_name_lower or "p3" in item_name_lower:
                return True, doppler_type, "Phase3"
            elif "phase 4" in item_name_lower or "p4" in item_name_lower:
                return True, doppler_type, "Phase4"
            else:
                return True, doppler_type, "Phase1"
        
        return False, "", ""
    
    def get_doppler_phases_from_api(self, good_detail: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ä»APIè¿”å›çš„good_detailä¸­è·å–å¤šæ™®å‹’Phaseä¿¡æ¯"""
        dpl_data = self.safe_get(good_detail, "data", "dpl", default=[])
        if not dpl_data:
            return []
        
        phases = []
        for phase_info in dpl_data:
            phase = {
                "key": phase_info.get("key"),
                "label": phase_info.get("label"),
                "value": phase_info.get("value"),
                "def_index": phase_info.get("def_index"),
                "paint_index": phase_info.get("paint_index"),
                "short_name_en": phase_info.get("short_name_en"),
                "buff_sell_price": phase_info.get("buff_sell_price"),
                "buff_buy_price": phase_info.get("buff_buy_price")
            }
            phases.append(phase)
        
        return phases
    
    def split_doppler_items(self, items: List[Dict[str, Any]], good_details: Dict[str, Any]) -> List[Dict[str, Any]]:
        """å°†å¤šæ™®å‹’ç³»åˆ—ç‰©å“åˆ†å‰²ä¸ºç‹¬ç«‹çš„Phaseç‰©å“"""
        split_items = []
        
        for item in items:
            good_id = item.get("good_id", "")
            item_name = item.get("name", "")
            
            # æ£€æŸ¥APIè¿”å›çš„good_detailä¸­æ˜¯å¦æœ‰dplå­—æ®µ
            if good_id in good_details:
                detail = good_details[good_id]
                dpl_phases = self.get_doppler_phases_from_api(detail)
                
                if dpl_phases:
                    # è¿™æ˜¯ä¸€ä¸ªå¤šæ™®å‹’ç‰©å“ï¼Œéœ€è¦åˆ†å‰²
                    print(f"  ğŸ”ª å‘ç°å¤šæ™®å‹’ç‰©å“ï¼š{item_name}")
                    print(f"     åŒ…å« {len(dpl_phases)} ä¸ªPhase")
                    
                    for phase_info in dpl_phases:
                        phase_label = phase_info.get("label", "")
                        phase_value = phase_info.get("value", "")
                        
                        # åˆ›å»ºæ–°çš„ç‰©å“è®°å½•
                        new_item = item.copy()
                        new_item["original_name"] = item_name
                        new_item["original_good_id"] = good_id
                        new_item["name"] = f"{item_name} ({phase_label})"
                        new_item["doppler_phase"] = phase_label
                        new_item["doppler_value"] = phase_value
                        new_item["good_id"] = f"{good_id}_{phase_label}"
                        
                        # æ·»åŠ Phaseç‰¹å®šçš„ä»·æ ¼ä¿¡æ¯
                        if phase_info.get("buff_sell_price"):
                            new_item["buff_sell_price"] = phase_info["buff_sell_price"]
                        if phase_info.get("buff_buy_price"):
                            new_item["buff_buy_price"] = phase_info["buff_buy_price"]
                        
                        # æ·»åŠ Phaseç‰¹å®šçš„ç»Ÿè®¡ä¿¡æ¯
                        statistic_list = self.safe_get(detail, "data", "statistic_list", default=[])
                        for stat in statistic_list:
                            if stat.get("name") == phase_label:
                                new_item["phase_statistic"] = stat.get("statistic", 0)
                                new_item["phase_statistic_at"] = stat.get("statistic_at", "")
                                break
                        
                        split_items.append(new_item)
                        print(f"     âœ… åˆ›å»ºPhaseï¼š{phase_label} (ID: {new_item['good_id']})")
                else:
                    # éå¤šæ™®å‹’ç‰©å“ç›´æ¥æ·»åŠ 
                    split_items.append(item)
            else:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°good_detailï¼Œä½¿ç”¨åŸæ¥çš„åç§°åŒ¹é…æ–¹æ³•
                is_doppler, doppler_type, phase = self.is_doppler_item(item_name)
                if is_doppler:
                    new_item = item.copy()
                    new_item["original_name"] = item_name
                    new_item["name"] = f"{item_name} ({doppler_type} {phase})"
                    new_item["doppler_type"] = doppler_type
                    new_item["doppler_phase"] = phase
                    new_item["good_id"] = f"{item['good_id']}_{phase}"
                    split_items.append(new_item)
                else:
                    split_items.append(item)
        
        return split_items
    
    def fetch_knife_universe(self, item_type: str, keywords: List[str], 
                           max_pages: int = 8, page_size: int = 50, 
                           test_mode: bool = False, max_items: int = None) -> List[str]:
        """è·å–æŒ‡å®šç‰©å“ç±»å‹çš„å•†å“IDåˆ—è¡¨"""
        print(f"ğŸ” æœç´¢ {item_type} å•†å“...")
        
        results = []
        seen = set()
        
        for keyword in keywords:
            print(f"  æœç´¢å…³é”®è¯ï¼š{keyword}")
            for page in range(1, max_pages + 1):
                try:
                    resp = self.client.get_good_id(keyword, page_index=page, page_size=page_size)
                    data = self.safe_get(resp, "data", "data", default={})
                    if not data:
                        break
                    
                    for gid_str, rec in data.items():
                        name = rec.get("name", rec.get("market_hash_name", "")).lower()
                        if any(kw.lower() in name for kw in keywords):
                            if gid_str not in seen:
                                seen.add(gid_str)
                                results.append(gid_str)
                    
                    time.sleep(1)  # é¿å…APIé™åˆ¶
                    
                except Exception as e:
                    print(f"    æœç´¢å¤±è´¥ï¼š{e}")
                    continue
        
        # ä»·æ ¼è¿‡æ»¤
        filtered = []
        print(f"  ä»·æ ¼è¿‡æ»¤ {len(results)} ä¸ªå€™é€‰å•†å“...")
        
        for i, gid in enumerate(results):
            if test_mode and max_items is not None and i >= max_items:  # æµ‹è¯•æ¨¡å¼å¤„ç†æŒ‡å®šæ•°é‡çš„ç‰©å“
                break
                
            if i % 10 == 0:
                print(f"    å¤„ç†è¿›åº¦ï¼š{i+1}/{min(len(results), 3 if test_mode else len(results))}")
            
            try:
                det = self.client.good_detail(gid)
                info = self.safe_get(det, "data", default={})
                
                # å°è¯•å¤šä¸ªä»·æ ¼å­—æ®µ
                candidates = []
                for k in ["buff_sell_price", "yyyp_sell_price",
                          "buffBuyPrice", "yyypBuyPrice",
                          "buffSellPrice", "yyypSellPrice"]:
                    v = info.get(k)
                    if v is not None:
                        try:
                            v = float(v)
                        except:
                            v = np.nan
                        if np.isfinite(v) and v > 0:
                            candidates.append(v)
                
                if not candidates:
                    # batch_price å†è¯•
                    mhn = self.safe_get(info, "goods_info", "market_hash_name", default=None)
                    if mhn:
                        bp = self.client.batch_price([mhn])
                        succ = self.safe_get(bp, "data", "success", default={})
                        ditem = succ.get(mhn, {})
                        for k in ["buffSellPrice", "yyypSellPrice"]:
                            v = ditem.get(k)
                            if v is not None:
                                try:
                                    v = float(v)
                                except:
                                    v = np.nan
                                if np.isfinite(v) and v > 0:
                                    candidates.append(v)
                
                max_price = max(candidates) if candidates else 0
                if max_price >= MIN_PRICE_THRESHOLD:
                    filtered.append(gid)
                
                time.sleep(0.5)  # é¿å…APIé™åˆ¶
                
            except Exception as e:
                print(f"    è·å–å•†å“ {gid} è¯¦æƒ…å¤±è´¥ï¼š{e}")
                continue
        
        # æµ‹è¯•æ¨¡å¼ï¼šéšæœºé€‰æ‹©ä¸€ä¸ªå•†å“
        if test_mode and filtered:
            selected = random.choice(filtered)
            print(f"ğŸ² æµ‹è¯•æ¨¡å¼ï¼šéšæœºé€‰æ‹© {item_type} çš„ä¸€ä¸ªå•†å“ï¼š{selected}")
            filtered = [selected]
        
        print(f"âœ… {item_type} æ‰¾åˆ° {len(filtered)} ä¸ªç¬¦åˆæ¡ä»¶çš„å•†å“")
        return filtered
    
    def get_current_item_data(self, good_id: str, vol_data: Dict[str, int]) -> Dict[str, Any]:
        """è·å–å•ä¸ªå•†å“çš„å½“å‰æ•°æ®"""
        try:
            # è·å–å•†å“è¯¦æƒ…
            detail = self.client.good_detail(good_id)
            info = detail.get("data", {})
            goods_info = info.get("goods_info", {})
            
            # åŸºç¡€ä¿¡æ¯
            item_data = {
                "time": self.get_beijing_time(),
                "good_id": str(good_id),
                "name": goods_info.get("name", ""),
                "market_hash_name": goods_info.get("market_hash_name", ""),
                "exterior": goods_info.get("exterior", ""),
                "collection": goods_info.get("collection", "")
            }
            
            # ä½¿ç”¨batch_priceæ¥å£è·å–ä»·æ ¼å’Œæ•°é‡ä¿¡æ¯
            mhn = goods_info.get("market_hash_name")
            if mhn:
                try:
                    bp = self.client.batch_price([mhn])
                    succ = bp.get("data", {}).get("success", {})
                    if mhn in succ:
                        ditem = succ[mhn]
                        
                        # æ ¹æ®APIæ–‡æ¡£ï¼Œå­—æ®µåæ˜¯é©¼å³°å‘½åæ³•
                        item_data["BUFF_sell_price"] = ditem.get("buffSellPrice", np.nan)
                        item_data["YYYP_sell_price"] = ditem.get("yyypSellPrice", np.nan)
                        item_data["BUFF_buy_price"] = ditem.get("buffBuyPrice", np.nan)  # å¯èƒ½ä¸å­˜åœ¨
                        item_data["YYYP_buy_price"] = ditem.get("yyypBuyPrice", np.nan)  # å¯èƒ½ä¸å­˜åœ¨
                        item_data["BUFF_sell_num"] = ditem.get("buffSellNum", np.nan)
                        item_data["YYYP_sell_num"] = ditem.get("yyypSellNum", np.nan)
                        item_data["BUFF_buy_num"] = ditem.get("buffBuyNum", np.nan)  # å¯èƒ½ä¸å­˜åœ¨
                        item_data["YYYP_buy_num"] = ditem.get("yyypBuyNum", np.nan)  # å¯èƒ½ä¸å­˜åœ¨
                        
                        print(f"    âœ… ä»batch_priceè·å–åˆ°æ•°æ®")
                    else:
                        print(f"    âŒ åœ¨batch_priceä¸­æœªæ‰¾åˆ°å•†å“: {mhn}")
                        # è®¾ç½®é»˜è®¤å€¼
                        for field in ["BUFF_sell_price", "YYYP_sell_price", "BUFF_buy_price", "YYYP_buy_price",
                                     "BUFF_sell_num", "YYYP_sell_num", "BUFF_buy_num", "YYYP_buy_num"]:
                            item_data[field] = np.nan
                except Exception as e:
                    print(f"    âŒ è·å–batch_priceå¤±è´¥: {e}")
                    # è®¾ç½®é»˜è®¤å€¼
                    for field in ["BUFF_sell_price", "YYYP_sell_price", "BUFF_buy_price", "YYYP_buy_price",
                                 "BUFF_sell_num", "YYYP_sell_num", "BUFF_buy_num", "YYYP_buy_num"]:
                        item_data[field] = np.nan
            else:
                print(f"    âŒ æ— æ³•è·å–market_hash_name")
                # è®¾ç½®é»˜è®¤å€¼
                for field in ["BUFF_sell_price", "YYYP_sell_price", "BUFF_buy_price", "YYYP_buy_price",
                             "BUFF_sell_num", "YYYP_sell_num", "BUFF_buy_num", "YYYP_buy_num"]:
                    item_data[field] = np.nan
            
            # æˆäº¤é‡ä¿¡æ¯
            item_data["BUFF_statistic"] = vol_data.get(str(good_id), 0)
            item_data["YYYP_statistic"] = vol_data.get(str(good_id), 0)  # æš‚æ—¶ä½¿ç”¨ç›¸åŒå€¼
            
            # æ‰“å°è°ƒè¯•ä¿¡æ¯
            print(f"    å•†å“ID: {good_id}")
            print(f"    å•†å“åç§°: {item_data['name']}")
            print(f"    BUFFå”®ä»·: {item_data.get('BUFF_sell_price', 'N/A')}")
            print(f"    YYYPå”®ä»·: {item_data.get('YYYP_sell_price', 'N/A')}")
            print(f"    BUFFæ±‚è´­: {item_data.get('BUFF_buy_price', 'N/A')}")
            print(f"    YYYPæ±‚è´­: {item_data.get('YYYP_buy_price', 'N/A')}")
            print(f"    BUFFåœ¨å”®: {item_data.get('BUFF_sell_num', 'N/A')}")
            print(f"    YYYPåœ¨å”®: {item_data.get('YYYP_sell_num', 'N/A')}")
            print(f"    BUFFæ±‚è´­æ•°: {item_data.get('BUFF_buy_num', 'N/A')}")
            print(f"    YYYPæ±‚è´­æ•°: {item_data.get('YYYP_buy_num', 'N/A')}")
            
            return item_data
            
        except Exception as e:
            print(f"    è·å–å•†å“ {good_id} å½“å‰æ•°æ®å¤±è´¥ï¼š{e}")
            return {
                "time": self.get_beijing_time(),
                "good_id": str(good_id),
                "name": f"Unknown {good_id}",
                "market_hash_name": "",
                "exterior": "",
                "collection": "",
                "BUFF_sell_price": np.nan,
                "YYYP_sell_price": np.nan,
                "BUFF_buy_price": np.nan,
                "YYYP_buy_price": np.nan,
                "BUFF_sell_num": np.nan,
                "YYYP_sell_num": np.nan,
                "BUFF_buy_num": np.nan,
                "YYYP_buy_num": np.nan,
                "BUFF_statistic": vol_data.get(str(good_id), 0),
                "YYYP_statistic": vol_data.get(str(good_id), 0)
            }
    
    def get_skin_type(self, item_name: str, exterior: str, collection: str) -> str:
        """æ ¹æ®ç‰©å“åç§°ã€å¤–è§‚å’Œæ”¶è—å“ç¡®å®šçš®è‚¤ç±»å‹"""
        # æå–çš®è‚¤ç±»å‹
        if "å¤šæ™®å‹’" in item_name or "doppler" in item_name.lower():
            if "çº¢å®çŸ³" in item_name or "ruby" in item_name.lower():
                return "çº¢å®çŸ³"
            elif "è“å®çŸ³" in item_name or "sapphire" in item_name.lower():
                return "è“å®çŸ³"
            elif "ç»¿å®çŸ³" in item_name or "emerald" in item_name.lower():
                return "ç»¿å®çŸ³"
            elif "phase" in item_name.lower():
                # æå–Phaseä¿¡æ¯
                if "phase 1" in item_name.lower() or "p1" in item_name.lower():
                    return "Phase1"
                elif "phase 2" in item_name.lower() or "p2" in item_name.lower():
                    return "Phase2"
                elif "phase 3" in item_name.lower() or "p3" in item_name.lower():
                    return "Phase3"
                elif "phase 4" in item_name.lower() or "p4" in item_name.lower():
                    return "Phase4"
                else:
                    return "å¤šæ™®å‹’"
            else:
                return "å¤šæ™®å‹’"
        
        # å…¶ä»–çš®è‚¤ç±»å‹
        skin_keywords = [
            "è“é’¢", "blue steel", "åŒ—æ–¹æ£®æ—", "boreal forest", "éƒ½å¸‚å±æœº", "urban masked",
            "æ·±çº¢ä¹‹ç½‘", "crimson web", "è‡´å‘½ç´«ç½—å…°", "fade", "æ¸å˜", "fade",
            "è™ç‰™", "tiger tooth", "å¤§ç†çŸ³", "marble fade", "å¤šæ™®å‹’", "doppler",
            "ä¼½é©¬å¤šæ™®å‹’", "gamma doppler", "è‡ªåŠ¨", "autotronic", "é»‘è‰²å±‚å‹æ¿", "black laminate",
            "è‡ªç”±ä¹‹æ‰‹", "freehand", "å± å¤«", "slaughter", "å™©æ¢¦", "nightmare",
            "è¡€ç½‘", "blood web", "è¡€ç½‘", "blood web", "è¡€ç½‘", "blood web"
        ]
        
        item_name_lower = item_name.lower()
        for i in range(0, len(skin_keywords), 2):
            chinese = skin_keywords[i]
            english = skin_keywords[i + 1]
            if chinese in item_name or english in item_name_lower:
                return chinese
        
        # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°ç‰¹å®šçš®è‚¤ï¼Œä½¿ç”¨å¤–è§‚
        if exterior:
            return exterior
        else:
            return "é»˜è®¤"
    
    def save_item_data(self, item_type: str, item_data: Dict[str, Any]):
        """ä¿å­˜å•ä¸ªå•†å“æ•°æ®åˆ°æŒ‡å®šç›®å½•ç»“æ„"""
        try:
            # è·å–ç‰©å“ç±»å‹æ‰€å±çš„ç±»åˆ«
            category = self.get_category_for_item_type(item_type)
            
            # åˆ›å»ºç›®å½•ç»“æ„ï¼šdataset/ç±»åˆ«/ç‰©å“ç±»å‹/
            item_dir = os.path.join(self.dataset_dir, category, item_type)
            self.ensure_dir(item_dir)
            
            # æ–‡ä»¶åï¼šä½¿ç”¨å•†å“IDå’Œåç§°ï¼Œç¡®ä¿æ¯ä¸ªå•†å“ç‹¬ç«‹
            good_id = item_data.get("good_id", "")
            item_name = item_data.get("name", "")
            
            # æ¸…ç†æ–‡ä»¶å
            safe_name = self.sanitize_filename(item_name)
            csv_file = os.path.join(item_dir, f"{good_id}_{safe_name}.csv")
            
            # å‡†å¤‡æ•°æ®è¡Œ
            data_row = {
                "data": item_data["time"],
                "BUFF_sell_price": item_data.get("BUFF_sell_price", np.nan),
                "YYYP_sell_price": item_data.get("YYYP_sell_price", np.nan),
                "BUFF_buy_price": item_data.get("BUFF_buy_price", np.nan),
                "YYYP_buy_price": item_data.get("YYYP_buy_price", np.nan),
                "BUFF_sell_num": item_data.get("BUFF_sell_num", np.nan),
                "YYYP_sell_num": item_data.get("YYYP_sell_num", np.nan),
                "BUFF_buy_num": item_data.get("BUFF_buy_num", np.nan),
                "YYYP_buy_num": item_data.get("YYYP_buy_num", np.nan),
                "YYYP_lease_num": item_data.get("YYYP_lease_num", np.nan),
                "YYYP_transfer_price": item_data.get("YYYP_transfer_price", np.nan),
                "YYYP_lease_price": item_data.get("YYYP_lease_price", np.nan),
                "YYYP_long_lease_price": item_data.get("YYYP_long_lease_price", np.nan),
                "YYYP_lease_annual": item_data.get("YYYP_lease_annual", np.nan),
                "YYYP_long_lease_annual": item_data.get("YYYP_long_lease_annual", np.nan),
                "BUFF_statistic": item_data.get("BUFF_statistic", 0),
                "YYYP_statistic": item_data.get("YYYP_statistic", 0),
                "good_id": item_data["good_id"]
            }
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if os.path.exists(csv_file):
                # æ–‡ä»¶å­˜åœ¨ï¼Œè¿½åŠ æ•°æ®
                df = pd.DataFrame([data_row])
                df.to_csv(csv_file, mode='a', header=False, index=False, encoding='utf-8')
                print(f"    ğŸ“ è¿½åŠ æ•°æ®åˆ°ï¼š{os.path.abspath(csv_file)}")
            else:
                # æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°æ–‡ä»¶
                df = pd.DataFrame([data_row])
                df.to_csv(csv_file, index=False, encoding='utf-8')
                print(f"    ğŸ“„ åˆ›å»ºæ–°æ–‡ä»¶ï¼š{os.path.abspath(csv_file)}")
            
            return csv_file
                
        except Exception as e:
            print(f"    âŒ ä¿å­˜æ•°æ®å¤±è´¥ï¼š{e}")
            return None
    
    def save_item_data_thread_safe(self, item_type: str, item_data: Dict[str, Any]) -> str:
        """çº¿ç¨‹å®‰å…¨çš„ä¿å­˜å•ä¸ªå•†å“æ•°æ®"""
        try:
            # è·å–ç‰©å“ç±»å‹æ‰€å±çš„ç±»åˆ«
            category = self.get_category_for_item_type(item_type)
            
            # åˆ›å»ºç›®å½•ç»“æ„ï¼šdataset/ç±»åˆ«/ç‰©å“ç±»å‹/
            item_dir = os.path.join(self.dataset_dir, category, item_type)
            os.makedirs(item_dir, exist_ok=True)
            
            # æ–‡ä»¶å
            good_id = item_data.get("good_id", "")
            item_name = item_data.get("name", "")
            safe_name = self.sanitize_filename(item_name)
            csv_file = os.path.join(item_dir, f"{good_id}_{safe_name}.csv")
            
            # è·å–æ–‡ä»¶é”
            if csv_file not in self.file_locks:
                with self.lock:
                    if csv_file not in self.file_locks:
                        self.file_locks[csv_file] = threading.Lock()
            
            file_lock = self.file_locks[csv_file]
            
            with file_lock:
                # å‡†å¤‡æ•°æ®è¡Œ
                data_row = {
                    "data": item_data["time"],
                    "BUFF_sell_price": item_data.get("BUFF_sell_price", np.nan),
                    "YYYP_sell_price": item_data.get("YYYP_sell_price", np.nan),
                    "BUFF_buy_price": item_data.get("BUFF_buy_price", np.nan),
                    "YYYP_buy_price": item_data.get("YYYP_buy_price", np.nan),
                    "BUFF_sell_num": item_data.get("BUFF_sell_num", np.nan),
                    "YYYP_sell_num": item_data.get("YYYP_sell_num", np.nan),
                    "BUFF_buy_num": item_data.get("BUFF_buy_num", np.nan),
                    "YYYP_buy_num": item_data.get("YYYP_buy_num", np.nan),
                    "YYYP_lease_num": item_data.get("YYYP_lease_num", np.nan),
                    "YYYP_transfer_price": item_data.get("YYYP_transfer_price", np.nan),
                    "YYYP_lease_price": item_data.get("YYYP_lease_price", np.nan),
                    "YYYP_long_lease_price": item_data.get("YYYP_long_lease_price", np.nan),
                    "YYYP_lease_annual": item_data.get("YYYP_lease_annual", np.nan),
                    "YYYP_long_lease_annual": item_data.get("YYYP_long_lease_annual", np.nan),
                    "BUFF_statistic": item_data.get("BUFF_statistic", 0),
                    "YYYP_statistic": item_data.get("YYYP_statistic", 0),
                    "good_id": item_data["good_id"]
                }
                
                # ä¿å­˜æ•°æ®
                if os.path.exists(csv_file):
                    df = pd.DataFrame([data_row])
                    df.to_csv(csv_file, mode='a', header=False, index=False, encoding='utf-8')
                else:
                    df = pd.DataFrame([data_row])
                    df.to_csv(csv_file, index=False, encoding='utf-8')
            
            return csv_file
            
        except Exception as e:
            print(f"âŒ ä¿å­˜å•†å“ {item_data['good_id']} æ•°æ®å¤±è´¥ï¼š{e}")
            return None
    
    def process_good_detail(self, good_id: str, detail: Dict[str, Any], cached_info: Dict[str, Any], vol_data: Dict[str, int], item_type: str) -> List[Dict[str, Any]]:
        """å¤„ç†å•ä¸ªå•†å“è¯¦æƒ…æ•°æ®ï¼ˆå¤šçº¿ç¨‹å®‰å…¨ï¼‰"""
        try:
            goods_info = detail.get("data", {}).get("goods_info", {})
            dpl_list = detail.get("data", {}).get("dpl", [])
            
            # æ„å»ºåŸºç¡€æ•°æ®
            item_data = {
                "time": self.get_beijing_time(),
                "good_id": str(good_id),
                "name": cached_info.get("name", ""),
                "market_hash_name": cached_info.get("market_hash_name", ""),
                "exterior": "",
                "collection": ""
            }
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºå¤šæ™®å‹’ç³»åˆ—å•†å“
            if dpl_list and len(dpl_list) > 0:
                # å¤„ç†å¤šæ™®å‹’å˜ä½“
                all_items_data = []
                for dpl_item in dpl_list:
                    doppler_item_data = item_data.copy()
                    
                    # æ›´æ–°å•†å“ä¿¡æ¯
                    doppler_item_data["good_id"] = f"{good_id}_{dpl_item.get('key', 'unknown')}"
                    doppler_item_data["name"] = f"{item_data['name']} | {dpl_item.get('label', 'Unknown')}"
                    doppler_item_data["exterior"] = goods_info.get("exterior_localized_name", "")
                    doppler_item_data["collection"] = goods_info.get("group_hash_name", "")
                    
                    # ä½¿ç”¨å¤šæ™®å‹’å˜ä½“çš„ä»·æ ¼æ•°æ®
                    doppler_item_data["BUFF_sell_price"] = dpl_item.get("buff_sell_price", np.nan)
                    doppler_item_data["BUFF_buy_price"] = dpl_item.get("buff_buy_price", np.nan)
                    
                    # å…¶ä»–æ•°æ®ä½¿ç”¨åŸºç¡€å•†å“çš„ä¿¡æ¯
                    doppler_item_data["YYYP_sell_price"] = goods_info.get("yyyp_sell_price", np.nan)
                    doppler_item_data["YYYP_buy_price"] = goods_info.get("yyyp_buy_price", np.nan)
                    doppler_item_data["BUFF_sell_num"] = goods_info.get("buff_sell_num", np.nan)
                    doppler_item_data["YYYP_sell_num"] = goods_info.get("yyyp_sell_num", np.nan)
                    doppler_item_data["BUFF_buy_num"] = goods_info.get("buff_buy_num", np.nan)
                    doppler_item_data["YYYP_buy_num"] = goods_info.get("yyyp_buy_num", np.nan)
                    
                    # è·å–YYYPç§Ÿèµç›¸å…³ä¿¡æ¯
                    doppler_item_data["YYYP_lease_num"] = goods_info.get("yyyp_lease_num", np.nan)
                    doppler_item_data["YYYP_transfer_price"] = goods_info.get("yyyp_transfer_price", np.nan)
                    doppler_item_data["YYYP_lease_price"] = goods_info.get("yyyp_lease_price", np.nan)
                    doppler_item_data["YYYP_long_lease_price"] = goods_info.get("yyyp_long_lease_price", np.nan)
                    doppler_item_data["YYYP_lease_annual"] = goods_info.get("yyyp_lease_annual", np.nan)
                    doppler_item_data["YYYP_long_lease_annual"] = goods_info.get("yyyp_long_lease_annual", np.nan)
                    
                    # æˆäº¤é‡ä¿¡æ¯
                    doppler_item_data["BUFF_statistic"] = vol_data.get(str(good_id), 0)
                    doppler_item_data["YYYP_statistic"] = vol_data.get(str(good_id), 0)
                    
                    all_items_data.append(doppler_item_data)
                
                return all_items_data
            else:
                # å¤„ç†æ™®é€šå•†å“
                item_data["BUFF_sell_price"] = goods_info.get("buff_sell_price", np.nan)
                item_data["YYYP_sell_price"] = goods_info.get("yyyp_sell_price", np.nan)
                item_data["BUFF_buy_price"] = goods_info.get("buff_buy_price", np.nan)
                item_data["YYYP_buy_price"] = goods_info.get("yyyp_buy_price", np.nan)
                item_data["BUFF_sell_num"] = goods_info.get("buff_sell_num", np.nan)
                item_data["YYYP_sell_num"] = goods_info.get("yyyp_sell_num", np.nan)
                item_data["BUFF_buy_num"] = goods_info.get("buff_buy_num", np.nan)
                item_data["YYYP_buy_num"] = goods_info.get("yyyp_buy_num", np.nan)
                
                # è·å–YYYPç§Ÿèµç›¸å…³ä¿¡æ¯
                item_data["YYYP_lease_num"] = goods_info.get("yyyp_lease_num", np.nan)
                item_data["YYYP_transfer_price"] = goods_info.get("yyyp_transfer_price", np.nan)
                item_data["YYYP_lease_price"] = goods_info.get("yyyp_lease_price", np.nan)
                item_data["YYYP_long_lease_price"] = goods_info.get("yyyp_long_lease_price", np.nan)
                item_data["YYYP_lease_annual"] = goods_info.get("yyyp_lease_annual", np.nan)
                item_data["YYYP_long_lease_annual"] = goods_info.get("yyyp_long_lease_annual", np.nan)
                
                # è·å–å…¶ä»–æœ‰ç”¨ä¿¡æ¯
                item_data["exterior"] = goods_info.get("exterior_localized_name", "")
                item_data["collection"] = goods_info.get("group_hash_name", "")
                
                # æˆäº¤é‡ä¿¡æ¯
                item_data["BUFF_statistic"] = vol_data.get(str(good_id), 0)
                item_data["YYYP_statistic"] = vol_data.get(str(good_id), 0)
                
                return [item_data]
                
        except Exception as e:
            print(f"âŒ å¤„ç†å•†å“ {good_id} æ•°æ®å¤±è´¥ï¼š{e}")
            return []
    
    def process_good_worker(self, args):
        """å·¥ä½œçº¿ç¨‹å‡½æ•°ï¼šå¤„ç†å•ä¸ªå•†å“"""
        good_id, cached_info, vol_data, item_type = args
        
        try:
            # è·å–å•†å“è¯¦æƒ…
            detail = self.get_single_good_detail(good_id)
            if not detail:
                return []
            
            # å¤„ç†å•†å“æ•°æ®
            items_data = self.process_good_detail(good_id, detail, cached_info, vol_data, item_type)
            
            # å®æ—¶ä¿å­˜æ•°æ®
            saved_files = []
            for item_data in items_data:
                saved_file = self.save_item_data_thread_safe(item_type, item_data)
                if saved_file:
                    saved_files.append(saved_file)
            
            return saved_files
                
        except Exception as e:
            print(f"âŒ å¤„ç†å•†å“ {good_id} å¤±è´¥ï¼š{e}")
            return []
    
    def check_total_items_count(self, item_type: str, all_items_info: Dict[str, Any]) -> bool:
        """æ£€æŸ¥æ¨¡æ¿ç­›é€‰åçš„ç‰©å“æ•°é‡æ˜¯å¦è¶…è¿‡é™åˆ¶"""
        total_count = len(all_items_info)
        MAX_ITEMS_LIMIT = 1800
        
        print(f"ğŸ“Š æ¨¡æ¿ç­›é€‰åç‰©å“æ•°é‡æ£€æŸ¥ï¼š")
        print(f"  - {item_type} ç­›é€‰åç‰©å“æ•°é‡ï¼š{total_count}")
        print(f"  - é™åˆ¶æ•°é‡ï¼š{MAX_ITEMS_LIMIT}")
        
        if total_count > MAX_ITEMS_LIMIT:
            print(f"âŒ ç‰©å“æ•°é‡è¶…è¿‡é™åˆ¶ï¼")
            print(f"  - å½“å‰æ•°é‡ï¼š{total_count}")
            print(f"  - é™åˆ¶æ•°é‡ï¼š{MAX_ITEMS_LIMIT}")
            print(f"  - è¶…å‡ºæ•°é‡ï¼š{total_count - MAX_ITEMS_LIMIT}")
            print(f"ğŸ›‘ åœæ­¢æ„å»ºæ•°æ®é›†")
            return False
        else:
            print(f"âœ… ç‰©å“æ•°é‡åœ¨é™åˆ¶èŒƒå›´å†…")
            return True
    
    def check_global_items_count(self, item_types: List[str]) -> bool:
        """æ£€æŸ¥å…¨å±€ç‰©å“æ•°é‡æ˜¯å¦è¶…è¿‡é™åˆ¶ï¼ˆçœŸå®æ¨¡æ¿ç­›é€‰åï¼‰"""
        MAX_ITEMS_LIMIT = 1800
        total_filtered_count = 0
        filtered_count_by_type = {}
        
        print(f"ğŸŒ å…¨å±€ç‰©å“æ•°é‡æ£€æŸ¥ï¼ˆçœŸå®æ¨¡æ¿ç­›é€‰åï¼‰ï¼š")
        
        for item_type in item_types:
            # è·å–ç‰©å“ç±»å‹çš„å…³é”®è¯
            all_types = self.get_all_item_types()
            if item_type not in all_types:
                continue
            
            # å°è¯•ä»ç¼“å­˜åŠ è½½å•†å“ä¿¡æ¯
            cache_data = self.load_cached_items(item_type)
            if cache_data and 'items' in cache_data:
                all_items_info = cache_data['items']
                
                # çœŸå®è¿›è¡Œæ¨¡æ¿ç­›é€‰ï¼ˆé™é»˜æ¨¡å¼ï¼‰
                filtered_items_info = self.filter_items_by_templates(item_type, all_items_info, verbose=False)
                filtered_count = len(filtered_items_info)
                
                total_filtered_count += filtered_count
                filtered_count_by_type[item_type] = filtered_count
                print(f"  - {item_type}: {len(all_items_info)} ä¸ª â†’ ç­›é€‰å {filtered_count} ä¸ª")
        
        print(f"  - æ€»è®¡ç­›é€‰åç‰©å“æ•°é‡ï¼š{total_filtered_count}")
        print(f"  - é™åˆ¶æ•°é‡ï¼š{MAX_ITEMS_LIMIT}")
        
        if total_filtered_count > MAX_ITEMS_LIMIT:
            print(f"âŒ å…¨å±€ç­›é€‰åç‰©å“æ•°é‡è¶…è¿‡é™åˆ¶ï¼")
            print(f"  - å½“å‰æ€»æ•°ï¼š{total_filtered_count}")
            print(f"  - é™åˆ¶æ•°é‡ï¼š{MAX_ITEMS_LIMIT}")
            print(f"  - è¶…å‡ºæ•°é‡ï¼š{total_filtered_count - MAX_ITEMS_LIMIT}")
            print(f"ğŸ›‘ åœæ­¢æ„å»ºæ•°æ®é›†")
            return False
        else:
            print(f"âœ… å…¨å±€ç­›é€‰åç‰©å“æ•°é‡åœ¨é™åˆ¶èŒƒå›´å†…")
            return True
    
    def sanitize_filename(self, filename: str) -> str:
        """æ¸…ç†æ–‡ä»¶å"""
        filename = re.sub(r'[<>:"/\\|?*]', '_', filename)
        filename = re.sub(r'\s+', ' ', filename).strip()
        filename = filename.replace('.', '_')
        filename = re.sub(r'[()ï¼ˆï¼‰â˜…â„¢]', '', filename)
        filename = re.sub(r'[|]', '_', filename)
        if len(filename) > 80:
            filename = filename[:80]
        if not filename.strip():
            filename = "Unknown_Item"
        return filename.strip()
    
    def build_item_database(self, item_type: str, keywords: List[str], test_mode: bool = False, max_items: int = None) -> List[str]:
        """æ„å»ºæŒ‡å®šç‰©å“ç±»å‹çš„å®æ—¶æ•°æ®åº“"""
        start_time = time.time()
        category_name = self.get_category_for_item_type(item_type)
        print(f"ğŸš€ å¼€å§‹è®°å½• {category_name} - {item_type} å®æ—¶æ•°æ®...")
        print(f"â° è®°å½•æ—¶é—´ï¼š{self.current_time}")
        
        if self.use_multithreading:
            print(f"âš™ï¸ å¤šçº¿ç¨‹æ¨¡å¼ï¼š{self.max_workers}ä¸ªçº¿ç¨‹ + å®æ—¶å†™å…¥")
        else:
            print(f"âš™ï¸ ä¸²è¡Œæ¨¡å¼ï¼šå•çº¿ç¨‹ + æ‰¹é‡å†™å…¥")
        
        # è·å–æˆäº¤é‡æ•°æ®
        print("ğŸ“Š è·å–æˆäº¤é‡æ•°æ®...")
        vol_data = self.get_vol_data_info()
        print(f"âœ… æˆåŠŸè·å– {len(vol_data)} ä¸ªç‰©å“çš„æˆäº¤é‡æ•°æ®")
        
        # å°è¯•ä»ç¼“å­˜åŠ è½½å•†å“ä¿¡æ¯
        refresh_cache = getattr(self, 'refresh_cache', False)
        use_cache = getattr(self, 'use_cache', False)
        
        if use_cache:
            # å¼ºåˆ¶ä½¿ç”¨ç¼“å­˜æ¨¡å¼
            cache_data = self.load_cached_items(item_type)
            if cache_data and 'items' in cache_data:
                all_items_info = cache_data['items']
                print(f"âœ… å¼ºåˆ¶ä½¿ç”¨ç¼“å­˜æ•°æ®ï¼Œè·³è¿‡æœç´¢é˜¶æ®µ")
            else:
                print(f"âŒ ç¼“å­˜ä¸å­˜åœ¨ï¼Œæ— æ³•å¼ºåˆ¶ä½¿ç”¨ç¼“å­˜æ¨¡å¼")
                return []
        elif refresh_cache:
            print(f"ğŸ”„ åˆ·æ–°ç¼“å­˜æ¨¡å¼ï¼Œé‡æ–°æœç´¢ {item_type}...")
            all_items_info = self.search_and_cache_items(item_type, keywords)
        else:
            cache_data = self.load_cached_items(item_type)
            if cache_data and 'items' in cache_data:
                all_items_info = cache_data['items']
                print(f"âœ… ä½¿ç”¨ç¼“å­˜æ•°æ®ï¼Œè·³è¿‡æœç´¢é˜¶æ®µ")
            else:
                # å¦‚æœæ²¡æœ‰ç¼“å­˜ï¼Œæœç´¢å¹¶ç¼“å­˜å•†å“ä¿¡æ¯
                print(f"ğŸ” é¦–æ¬¡æœç´¢ {item_type}ï¼Œæ­£åœ¨å»ºç«‹ç¼“å­˜...")
                all_items_info = self.search_and_cache_items(item_type, keywords)
        
        if not all_items_info:
            print(f"âŒ æœªæ‰¾åˆ° {item_type} çš„å•†å“")
            return []
        
        # æ ¹æ®æµ‹è¯•æ¨¡å¼å’Œé™åˆ¶æ•°é‡å¤„ç†å•†å“åˆ—è¡¨
        good_ids = list(all_items_info.keys())
        if test_mode and max_items:
            if len(good_ids) > max_items:
                import random
                # ä¼˜å…ˆé€‰æ‹©å¤šæ™®å‹’å•†å“è¿›è¡Œæµ‹è¯•ï¼ˆä»…å¯¹åŒ•é¦–ç±»åˆ«ï¼‰
                if category_name == "åŒ•é¦–":
                    doppler_good_ids = []
                    regular_good_ids = []
                    
                    for good_id in good_ids:
                        item_name = all_items_info[good_id].get("name", "")
                        if "å¤šæ™®å‹’" in item_name or "ä¼½ç›å¤šæ™®å‹’" in item_name:
                            doppler_good_ids.append(good_id)
                        else:
                            regular_good_ids.append(good_id)
                    
                    # å¦‚æœæœ‰å¤šæ™®å‹’å•†å“ï¼Œä¼˜å…ˆé€‰æ‹©
                    if doppler_good_ids:
                        selected_count = min(max_items, len(doppler_good_ids))
                        good_ids = random.sample(doppler_good_ids, selected_count)
                        print(f"ğŸ² æµ‹è¯•æ¨¡å¼ï¼šä¼˜å…ˆé€‰æ‹© {len(good_ids)} ä¸ªå¤šæ™®å‹’å•†å“")
                    else:
                        good_ids = random.sample(good_ids, max_items)
                        print(f"ğŸ² æµ‹è¯•æ¨¡å¼ï¼šéšæœºé€‰æ‹© {len(good_ids)} ä¸ªå•†å“")
                else:
                    good_ids = random.sample(good_ids, max_items)
                    print(f"ğŸ² æµ‹è¯•æ¨¡å¼ï¼šéšæœºé€‰æ‹© {len(good_ids)} ä¸ªå•†å“")
        elif max_items and len(good_ids) > max_items:
            good_ids = good_ids[:max_items]
            print(f"ğŸ“ é™åˆ¶æ•°é‡ï¼šé€‰æ‹©å‰ {len(good_ids)} ä¸ªå•†å“")
        
        print(f"âœ… {item_type} å‡†å¤‡å¤„ç† {len(good_ids)} ä¸ªå•†å“")
        
        # æ ¹æ®æ¨¡ç‰ˆé…ç½®ç­›é€‰å•†å“ï¼ˆå¯¹æ‰€æœ‰ç±»åˆ«éƒ½ç”Ÿæ•ˆï¼‰
        filtered_items_info = self.filter_items_by_templates(item_type, all_items_info)
        filtered_good_ids = list(filtered_items_info.keys())
        
        if len(filtered_good_ids) == 0:
            print(f"âŒ {item_type} æ¨¡ç‰ˆç­›é€‰åæ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„å•†å“")
            return []
        
        # æ£€æŸ¥æ¨¡æ¿ç­›é€‰åçš„ç‰©å“æ•°é‡æ˜¯å¦è¶…è¿‡é™åˆ¶
        if not self.check_total_items_count(item_type, filtered_items_info):
            return []
        
        print(f"ğŸ¯ {item_type} æœ€ç»ˆå¤„ç† {len(filtered_good_ids)} ä¸ªå•†å“")
        
        if self.use_multithreading:
            # å¤šçº¿ç¨‹å¤„ç†æ¨¡å¼
            return self._build_item_database_multithread(item_type, filtered_good_ids, filtered_items_info, vol_data)
        else:
            # ä¸²è¡Œå¤„ç†æ¨¡å¼ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
            return self._build_item_database_serial(item_type, filtered_good_ids, filtered_items_info, vol_data)
    
    def _build_item_database_multithread(self, item_type: str, good_ids: List[str], all_items_info: Dict[str, Any], vol_data: Dict[str, int]) -> List[str]:
        """å¤šçº¿ç¨‹æ¨¡å¼æ„å»ºæ•°æ®åº“"""
        start_time = time.time()  # æ·»åŠ start_timeå®šä¹‰
        print(f"ğŸš€ ä½¿ç”¨å¤šçº¿ç¨‹æ¨¡å¼å¤„ç† {len(good_ids)} ä¸ªå•†å“...")
        
        # å‡†å¤‡ä»»åŠ¡å‚æ•°
        tasks = []
        for good_id in good_ids:
            if good_id in all_items_info:
                cached_info = all_items_info[good_id]
                tasks.append((good_id, cached_info, vol_data, item_type))
        
        print(f"ğŸ“Š å‡†å¤‡å¤„ç† {len(tasks)} ä¸ªå•†å“...")
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¤„ç†
        all_saved_files = []
        completed_count = 0
        
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_good_id = {executor.submit(self.process_good_worker, task): task[0] for task in tasks}
            
            # å¤„ç†å®Œæˆçš„ä»»åŠ¡
            for future in as_completed(future_to_good_id):
                good_id = future_to_good_id[future]
                try:
                    saved_files = future.result()
                    all_saved_files.extend(saved_files)
                    completed_count += 1
                    
                    # æ˜¾ç¤ºè¿›åº¦
                    if completed_count % 10 == 0 or completed_count == len(tasks):
                        progress = (completed_count / len(tasks)) * 100
                        print(f"ğŸ“ˆ è¿›åº¦ï¼š{completed_count}/{len(tasks)} ({progress:.1f}%) - å·²ä¿å­˜ {len(all_saved_files)} ä¸ªæ–‡ä»¶")
                        
                except Exception as e:
                    print(f"âŒ å¤„ç†å•†å“ {good_id} æ—¶å‘ç”Ÿå¼‚å¸¸ï¼š{e}")
        
        end_time = time.time()
        duration = end_time - start_time
        
        print(f"âœ… {item_type} å¤šçº¿ç¨‹å¤„ç†å®Œæˆ")
        print(f"  - å¤„ç†å•†å“ï¼š{completed_count} ä¸ª")
        print(f"  - ä¿å­˜æ–‡ä»¶ï¼š{len(all_saved_files)} ä¸ª")
        print(f"  - è€—æ—¶ï¼š{duration:.2f} ç§’")
        print(f"  - å¹³å‡è€—æ—¶ï¼š{duration/len(tasks):.2f} ç§’/å•†å“")
        print(f"  - APIè¯·æ±‚ï¼š{self.stats['successful_requests']}/{self.stats['total_requests']} æˆåŠŸ")
        print(f"  - é™æµæ¬¡æ•°ï¼š{self.stats['rate_limit_hits']}")
        
        return all_saved_files
    
    def _build_item_database_serial(self, item_type: str, good_ids: List[str], all_items_info: Dict[str, Any], vol_data: Dict[str, int]) -> List[str]:
        """ä¸²è¡Œæ¨¡å¼æ„å»ºæ•°æ®åº“ï¼ˆåŸæœ‰é€»è¾‘ï¼‰"""
        start_time = time.time()  # æ·»åŠ start_timeå®šä¹‰
        print(f"ğŸš€ ä½¿ç”¨ä¸²è¡Œæ¨¡å¼å¤„ç† {len(good_ids)} ä¸ªå•†å“...")
        
        # ç¬¬ä¸€æ­¥ï¼šæå–æ‰€æœ‰market_hash_nameï¼ˆä»ç¼“å­˜ä¸­è·å–ï¼Œé¿å…é‡å¤APIè°ƒç”¨ï¼‰
        print("ğŸ“¡ å‡†å¤‡æ‰¹é‡ä»·æ ¼æŸ¥è¯¢...")
        market_hash_names = []
        good_id_to_mhn = {}
        
        for good_id in good_ids:
            if good_id in all_items_info:
                mhn = all_items_info[good_id].get("market_hash_name")
                if mhn:
                    market_hash_names.append(mhn)
                    good_id_to_mhn[good_id] = mhn
        
        print(f"âœ… ä»ç¼“å­˜æå–åˆ° {len(market_hash_names)} ä¸ªæœ‰æ•ˆçš„market_hash_name")
        
        # ç¬¬äºŒæ­¥ï¼šè·å–æ‰€æœ‰å•†å“è¯¦ç»†ä¿¡æ¯ï¼ˆAPIåˆè§„ç‰ˆæœ¬ï¼‰
        print("ğŸ“Š è·å–å•†å“è¯¦ç»†ä¿¡æ¯ï¼ˆAPIåˆè§„æ¨¡å¼ï¼‰...")
        
        # ä½¿ç”¨APIåˆè§„çš„å•†å“è¯¦æƒ…è·å–
        good_details = self.get_all_good_details(good_ids)
        
        # å¤„ç†å•†å“è¯¦æƒ…æ•°æ®
        all_items_data = []
        
        for good_id, detail in good_details.items():
            if good_id not in all_items_info:
                continue
            
            cached_info = all_items_info[good_id]
            
            # æ„å»ºåŸºç¡€æ•°æ®
            item_data = {
                "time": self.get_beijing_time(),
                "good_id": str(good_id),
                "name": cached_info.get("name", ""),
                "market_hash_name": cached_info.get("market_hash_name", ""),
                "exterior": "",
                "collection": ""
            }
            
            try:
                goods_info = detail.get("data", {}).get("goods_info", {})
                dpl_list = detail.get("data", {}).get("dpl", [])
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºå¤šæ™®å‹’ç³»åˆ—å•†å“
                if dpl_list and len(dpl_list) > 0:
                    # è¿™æ˜¯å¤šæ™®å‹’ç³»åˆ—å•†å“ï¼Œéœ€è¦ä¸ºæ¯ä¸ªå˜ä½“åˆ›å»ºç‹¬ç«‹çš„æ•°æ®
                    print(f"    ğŸ” å‘ç°å¤šæ™®å‹’ç³»åˆ—å•†å“ï¼ŒåŒ…å« {len(dpl_list)} ä¸ªå˜ä½“")
                    
                    # ä¸ºæ¯ä¸ªå¤šæ™®å‹’å˜ä½“åˆ›å»ºç‹¬ç«‹çš„æ•°æ®é¡¹
                    for dpl_item in dpl_list:
                        # åˆ›å»ºæ–°çš„æ•°æ®é¡¹
                        doppler_item_data = item_data.copy()
                        
                        # æ›´æ–°å•†å“ä¿¡æ¯
                        doppler_item_data["good_id"] = f"{good_id}_{dpl_item.get('key', 'unknown')}"
                        doppler_item_data["name"] = f"{item_data['name']} | {dpl_item.get('label', 'Unknown')}"
                        doppler_item_data["exterior"] = goods_info.get("exterior_localized_name", "")
                        doppler_item_data["collection"] = goods_info.get("group_hash_name", "")
                        
                        # ä½¿ç”¨å¤šæ™®å‹’å˜ä½“çš„ä»·æ ¼æ•°æ®
                        doppler_item_data["BUFF_sell_price"] = dpl_item.get("buff_sell_price", np.nan)
                        doppler_item_data["BUFF_buy_price"] = dpl_item.get("buff_buy_price", np.nan)
                        
                        # å…¶ä»–æ•°æ®ä½¿ç”¨åŸºç¡€å•†å“çš„ä¿¡æ¯
                        doppler_item_data["YYYP_sell_price"] = goods_info.get("yyyp_sell_price", np.nan)
                        doppler_item_data["YYYP_buy_price"] = goods_info.get("yyyp_buy_price", np.nan)
                        doppler_item_data["BUFF_sell_num"] = goods_info.get("buff_sell_num", np.nan)
                        doppler_item_data["YYYP_sell_num"] = goods_info.get("yyyp_sell_num", np.nan)
                        doppler_item_data["BUFF_buy_num"] = goods_info.get("buff_buy_num", np.nan)
                        doppler_item_data["YYYP_buy_num"] = goods_info.get("yyyp_buy_num", np.nan)
                        
                        # è·å–YYYPç§Ÿèµç›¸å…³ä¿¡æ¯
                        doppler_item_data["YYYP_lease_num"] = goods_info.get("yyyp_lease_num", np.nan)
                        doppler_item_data["YYYP_transfer_price"] = goods_info.get("yyyp_transfer_price", np.nan)
                        doppler_item_data["YYYP_lease_price"] = goods_info.get("yyyp_lease_price", np.nan)
                        doppler_item_data["YYYP_long_lease_price"] = goods_info.get("yyyp_long_lease_price", np.nan)
                        doppler_item_data["YYYP_lease_annual"] = goods_info.get("yyyp_lease_annual", np.nan)
                        doppler_item_data["YYYP_long_lease_annual"] = goods_info.get("yyyp_long_lease_annual", np.nan)
                        
                        # æˆäº¤é‡ä¿¡æ¯
                        doppler_item_data["BUFF_statistic"] = vol_data.get(str(good_id), 0)
                        doppler_item_data["YYYP_statistic"] = vol_data.get(str(good_id), 0)
                        
                        all_items_data.append(doppler_item_data)
                        
                        # æ‰“å°è°ƒè¯•ä¿¡æ¯ï¼ˆä»…æ˜¾ç¤ºå‰å‡ ä¸ªï¼‰
                        if len(all_items_data) <= 6:  # å¢åŠ æ˜¾ç¤ºæ•°é‡ï¼Œå› ä¸ºå¤šæ™®å‹’å•†å“ä¼šç”Ÿæˆå¤šä¸ªå˜ä½“
                            print(f"    ğŸ“Š å¤šæ™®å‹’å˜ä½“ {dpl_item.get('label', 'Unknown')}: {doppler_item_data['name']}")
                            print(f"      BUFFå”®ä»·: {doppler_item_data.get('BUFF_sell_price', 'N/A')}")
                            print(f"      BUFFæ±‚è´­: {doppler_item_data.get('BUFF_buy_price', 'N/A')}")
                            print(f"      YYYPå”®ä»·: {doppler_item_data.get('YYYP_sell_price', 'N/A')}")
                            print(f"      YYYPæ±‚è´­: {doppler_item_data.get('YYYP_buy_price', 'N/A')}")
                    
                    # è·³è¿‡åŸå§‹å•†å“çš„å¤„ç†ï¼Œå› ä¸ºå·²ç»ä¸ºæ¯ä¸ªå˜ä½“åˆ›å»ºäº†ç‹¬ç«‹æ•°æ®
                    continue
                    
                else:
                    # æ™®é€šå•†å“ï¼Œä½¿ç”¨åŸæœ‰é€»è¾‘
                    # ä»è¯¦ç»†ä¿¡æ¯ä¸­è·å–ä»·æ ¼å’Œæ•°é‡æ•°æ®
                    item_data["BUFF_sell_price"] = goods_info.get("buff_sell_price", np.nan)
                    item_data["YYYP_sell_price"] = goods_info.get("yyyp_sell_price", np.nan)
                    item_data["BUFF_buy_price"] = goods_info.get("buff_buy_price", np.nan)
                    item_data["YYYP_buy_price"] = goods_info.get("yyyp_buy_price", np.nan)
                    item_data["BUFF_sell_num"] = goods_info.get("buff_sell_num", np.nan)
                    item_data["YYYP_sell_num"] = goods_info.get("yyyp_sell_num", np.nan)
                    item_data["BUFF_buy_num"] = goods_info.get("buff_buy_num", np.nan)
                    item_data["YYYP_buy_num"] = goods_info.get("yyyp_buy_num", np.nan)
                    
                    # è·å–YYYPç§Ÿèµç›¸å…³ä¿¡æ¯
                    item_data["YYYP_lease_num"] = goods_info.get("yyyp_lease_num", np.nan)
                    item_data["YYYP_transfer_price"] = goods_info.get("yyyp_transfer_price", np.nan)
                    item_data["YYYP_lease_price"] = goods_info.get("yyyp_lease_price", np.nan)
                    item_data["YYYP_long_lease_price"] = goods_info.get("yyyp_long_lease_price", np.nan)
                    item_data["YYYP_lease_annual"] = goods_info.get("yyyp_lease_annual", np.nan)
                    item_data["YYYP_long_lease_annual"] = goods_info.get("yyyp_long_lease_annual", np.nan)
                    
                    # è·å–å…¶ä»–æœ‰ç”¨ä¿¡æ¯
                    item_data["exterior"] = goods_info.get("exterior_localized_name", "")
                    item_data["collection"] = goods_info.get("group_hash_name", "")
                    
                    # æˆäº¤é‡ä¿¡æ¯
                    item_data["BUFF_statistic"] = vol_data.get(str(good_id), 0)
                    item_data["YYYP_statistic"] = vol_data.get(str(good_id), 0)
                    
                    all_items_data.append(item_data)
                    
                    # æ‰“å°è°ƒè¯•ä¿¡æ¯ï¼ˆä»…æ˜¾ç¤ºå‰å‡ ä¸ªï¼‰
                    if len(all_items_data) <= 3:
                        print(f"    ğŸ“Š å•†å“ {good_id}: {item_data['name']}")
                        print(f"      BUFFå”®ä»·: {item_data.get('BUFF_sell_price', 'N/A')}")
                        print(f"      YYYPå”®ä»·: {item_data.get('YYYP_sell_price', 'N/A')}")
                        print(f"      BUFFæ±‚è´­: {item_data.get('BUFF_buy_price', 'N/A')}")
                        print(f"      YYYPæ±‚è´­: {item_data.get('YYYP_buy_price', 'N/A')}")
                        print(f"      BUFFåœ¨å”®: {item_data.get('BUFF_sell_num', 'N/A')}")
                        print(f"      YYYPåœ¨å”®: {item_data.get('YYYP_sell_num', 'N/A')}")
                        print(f"      BUFFæ±‚è´­æ•°: {item_data.get('BUFF_buy_num', 'N/A')}")
                        print(f"      YYYPæ±‚è´­æ•°: {item_data.get('YYYP_buy_num', 'N/A')}")
                        print(f"      YYYPåœ¨ç§Ÿ: {item_data.get('YYYP_lease_num', 'N/A')}")
                        print(f"      YYYPè¿‡æˆ·ä»·: {item_data.get('YYYP_transfer_price', 'N/A')}")
                        print(f"      YYYPçŸ­ç§Ÿä»·: {item_data.get('YYYP_lease_price', 'N/A')}")
                        print(f"      YYYPé•¿ç§Ÿä»·: {item_data.get('YYYP_long_lease_price', 'N/A')}")
                        print(f"      YYYPçŸ­ç§Ÿå¹´åŒ–: {item_data.get('YYYP_lease_annual', 'N/A')}%")
                        print(f"      YYYPé•¿ç§Ÿå¹´åŒ–: {item_data.get('YYYP_long_lease_annual', 'N/A')}%")
                
            except Exception as e:
                print(f"    âŒ å¤„ç†å•†å“ {good_id} æ•°æ®å¤±è´¥ï¼š{e}")
                # è®¾ç½®é»˜è®¤å€¼
                for field in ["BUFF_sell_price", "YYYP_sell_price", "BUFF_buy_price", "YYYP_buy_price",
                             "BUFF_sell_num", "YYYP_sell_num", "BUFF_buy_num", "YYYP_buy_num",
                             "YYYP_lease_num", "YYYP_transfer_price", "YYYP_lease_price", 
                             "YYYP_long_lease_price", "YYYP_lease_annual", "YYYP_long_lease_annual"]:
                    item_data[field] = np.nan
                
                # æˆäº¤é‡ä¿¡æ¯
                item_data["BUFF_statistic"] = vol_data.get(str(good_id), 0)
                item_data["YYYP_statistic"] = vol_data.get(str(good_id), 0)
                
                all_items_data.append(item_data)
        
        print(f"âœ… æˆåŠŸè·å– {len(all_items_data)} ä¸ªå•†å“çš„å®Œæ•´æ•°æ®")
        
        # ç¬¬å››æ­¥ï¼šä¿å­˜æ•°æ®
        print("ğŸ’¾ ä¿å­˜æ•°æ®åˆ°æ–‡ä»¶...")
        saved_files = []
        for item_data in all_items_data:
            try:
                saved_file = self.save_item_data(item_type, item_data)
                if saved_file:
                    saved_files.append(saved_file)
            except Exception as e:
                print(f"âŒ ä¿å­˜å•†å“ {item_data['good_id']} æ•°æ®å¤±è´¥ï¼š{e}")
        
        end_time = time.time()
        duration = end_time - start_time
        
        print(f"âœ… {item_type} æ•°æ®è®°å½•å®Œæˆ")
        print(f"  - å¤„ç†å•†å“ï¼š{len(all_items_data)} ä¸ª")
        print(f"  - ä¿å­˜æ–‡ä»¶ï¼š{len(saved_files)} ä¸ª")
        print(f"  - è€—æ—¶ï¼š{duration:.2f} ç§’")
        print(f"  - APIè¯·æ±‚ï¼š{self.stats['successful_requests']}/{self.stats['total_requests']} æˆåŠŸ")
        print(f"  - é™æµæ¬¡æ•°ï¼š{self.stats['rate_limit_hits']}")
        
        return saved_files
    
    def run(self, item_types: List[str] = None, test_mode: bool = False, max_items: int = None, category: str = None):
        """è¿è¡Œå®æ—¶æ•°æ®è®°å½•æµç¨‹"""
        if category:
            # å¦‚æœæŒ‡å®šäº†ç±»åˆ«ï¼Œåªå¤„ç†è¯¥ç±»åˆ«ä¸‹çš„ç‰©å“ç±»å‹
            item_types = list(ITEM_CATEGORIES.get(category, {}).keys())
            if not item_types:
                print(f"âŒ æœªæ‰¾åˆ°ç±»åˆ«ï¼š{category}")
                return {}
        elif item_types is None:
            # å¦‚æœæ²¡æœ‰æŒ‡å®šç±»åˆ«å’Œç‰©å“ç±»å‹ï¼Œå¤„ç†æ‰€æœ‰ç‰©å“ç±»å‹
            item_types = []
            for cat_items in ITEM_CATEGORIES.values():
                item_types.extend(list(cat_items.keys()))
        
        print(f"ğŸš€ å¼€å§‹è®°å½• {len(item_types)} ç§ç‰©å“ç±»å‹å®æ—¶æ•°æ®...")
        print(f"â° è®°å½•æ—¶é—´ï¼š{self.current_time}")
        if test_mode:
            print(f"ğŸ§ª æµ‹è¯•æ¨¡å¼ï¼šæ¯ä¸ªç‰©å“ç±»å‹éšæœºé€‰æ‹©1ä¸ªç‰©å“")
        
        # æ£€æŸ¥å…¨å±€ç‰©å“æ•°é‡æ˜¯å¦è¶…è¿‡é™åˆ¶
        if not self.check_global_items_count(item_types):
            return {}
        
        # ç¡®ä¿ä¸»ç›®å½•å­˜åœ¨
        self.ensure_dir(self.dataset_dir)
        
        results = {}
        
        for item_type in item_types:
            # è·å–ç‰©å“ç±»å‹çš„å…³é”®è¯
            all_types = self.get_all_item_types()
            if item_type not in all_types:
                print(f"âš ï¸ æœªçŸ¥ç‰©å“ç±»å‹ï¼š{item_type}")
                continue
            
            keywords = all_types[item_type]
            category_name = self.get_category_for_item_type(item_type)
            
            try:
                # è®°å½•æ•°æ®
                saved_files = self.build_item_database(item_type, keywords, test_mode=test_mode, max_items=max_items)
                    
                results[item_type] = {
                    'saved_files': len(saved_files) if saved_files else 0,
                    'success': True,
                    'category': category_name
                }
                
            except Exception as e:
                print(f"âŒ {item_type} è®°å½•å¤±è´¥ï¼š{e}")
                results[item_type] = {'success': False, 'error': str(e), 'category': category_name}
            
            print(f"\n{'='*50}")
        
        # æ‰“å°æ€»ç»“
        total_time = time.time() - self.stats['start_time']
        success_count = sum(1 for r in results.values() if r.get('success', False))
        
        print("\nğŸ“Š è®°å½•æ€»ç»“ï¼š")
        print(f"  - æˆåŠŸè®°å½•ï¼š{success_count}/{len(item_types)} ç§ç‰©å“ç±»å‹")
        print(f"  - æ€»è€—æ—¶ï¼š{total_time:.2f} ç§’")
        print(f"  - å¹³å‡è€—æ—¶ï¼š{total_time/len(item_types):.2f} ç§’/ç‰©å“ç±»å‹")
        print(f"  - APIæˆåŠŸç‡ï¼š{self.stats['successful_requests']}/{self.stats['total_requests']} ({self.stats['successful_requests']/max(self.stats['total_requests'], 1)*100:.1f}%)")
        print(f"  - é™æµæ¬¡æ•°ï¼š{self.stats['rate_limit_hits']}")
        print(f"  - åˆè§„æ€§ï¼šâœ… å®Œå…¨ç¬¦åˆ1æ¬¡/ç§’APIé™åˆ¶")
        if self.use_multithreading:
            print(f"  - å¤„ç†æ¨¡å¼ï¼šğŸš€ å¤šçº¿ç¨‹æ¨¡å¼ï¼ˆ{self.max_workers}çº¿ç¨‹ + å®æ—¶å†™å…¥ï¼‰")
        else:
            print(f"  - å¤„ç†æ¨¡å¼ï¼šğŸ“ ä¸²è¡Œæ¨¡å¼ï¼ˆå•çº¿ç¨‹ + æ‰¹é‡å†™å…¥ï¼‰")
        
        for item_type, result in results.items():
            if result.get('success', False):
                print(f"  âœ… {result.get('category', 'æœªçŸ¥')} - {item_type}: {result['saved_files']} ä¸ªæ–‡ä»¶")
            else:
                print(f"  âŒ {result.get('category', 'æœªçŸ¥')} - {item_type}: {result.get('error', 'Unknown error')}")
        
        return results
    
    def get_all_item_types(self, category: str = None) -> Dict[str, List[str]]:
        """è·å–æ‰€æœ‰ç‰©å“ç±»å‹"""
        if category:
            return ITEM_CATEGORIES.get(category, {})
        else:
            # è¿”å›æ‰€æœ‰ç±»åˆ«çš„æ‰€æœ‰ç‰©å“ç±»å‹
            all_types = {}
            for cat_name, cat_items in ITEM_CATEGORIES.items():
                all_types.update(cat_items)
            return all_types
    
    def get_category_for_item_type(self, item_type: str) -> str:
        """æ ¹æ®ç‰©å“ç±»å‹è·å–æ‰€å±ç±»åˆ«"""
        for category, items in ITEM_CATEGORIES.items():
            if item_type in items:
                return category
        return "æœªçŸ¥ç±»åˆ«"
    
    def is_valid_item_for_knife_type(self, item_name: str, knife_type: str) -> bool:
        """æ£€æŸ¥å•†å“æ˜¯å¦å±äºæŒ‡å®šçš„åˆ€å‹"""
        item_name_lower = item_name.lower()
        
        # ç‰¹æ®Šå¤„ç†M9åˆºåˆ€
        if knife_type == "M9åˆºåˆ€":
            # M9åˆºåˆ€å¿…é¡»åŒ…å«"M9"ä¸”åŒ…å«"åˆºåˆ€"
            return "m9" in item_name_lower and "åˆºåˆ€" in item_name_lower
        
        # ç‰¹æ®Šå¤„ç†æ™®é€šåˆºåˆ€
        if knife_type == "åˆºåˆ€":
            # æ™®é€šåˆºåˆ€å¿…é¡»åŒ…å«"åˆºåˆ€"ä½†ä¸åŒ…å«"M9"
            return "åˆºåˆ€" in item_name_lower and "m9" not in item_name_lower
        
        # å…¶ä»–åˆ€å‹çš„å¤„ç†
        # è·å–æ’é™¤å…³é”®è¯
        exclude_keywords = EXCLUDE_KEYWORDS.get(knife_type, [])
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ’é™¤å…³é”®è¯
        for exclude_keyword in exclude_keywords:
            if exclude_keyword.lower() in item_name_lower:
                return False
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ç›®æ ‡åˆ€å‹å…³é”®è¯
        target_keywords = KNIFE_KEYWORDS.get(knife_type, [])
        for keyword in target_keywords:
            if keyword.lower() in item_name_lower:
                return True
        
        return False
    
    def is_valid_item_for_type(self, item_name: str, item_type: str) -> bool:
        """æ£€æŸ¥å•†å“æ˜¯å¦å±äºæŒ‡å®šçš„ç‰©å“ç±»å‹ï¼ˆé€šç”¨ç‰ˆæœ¬ï¼‰"""
        item_name_lower = item_name.lower()
        
        # è·å–ç‰©å“ç±»å‹çš„å…³é”®è¯
        all_types = self.get_all_item_types()
        if item_type not in all_types:
            return False
        
        target_keywords = all_types[item_type]
        
        # è·å–æ’é™¤å…³é”®è¯
        exclude_keywords = EXCLUDE_KEYWORDS.get(item_type, [])
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æ’é™¤å…³é”®è¯
        for exclude_keyword in exclude_keywords:
            if exclude_keyword.lower() in item_name_lower:
                return False
        
        # ç‰¹æ®Šå¤„ç†æ¢å‘˜ç±»åˆ«
        if item_type in ["Tæ¢å‘˜", "CTæ¢å‘˜", "æ¢å‘˜"]:
            # æ¢å‘˜ç±»åˆ«ä¸åšå…³é”®è¯æ’é™¤ï¼Œç›´æ¥æ£€æŸ¥æ˜¯å¦åŒ…å«ç›®æ ‡å…³é”®è¯
            for keyword in target_keywords:
                if keyword.lower() in item_name_lower:
                    return True
            return False
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ç›®æ ‡å…³é”®è¯
        for keyword in target_keywords:
            if keyword.lower() in item_name_lower:
                return True
        
        return False

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="å®æ—¶è®°å½•ç‰©å“æ•°æ®ï¼ˆæ•´åˆç‰ˆæœ¬ï¼šæ”¯æŒåŒ•é¦–ã€æ¢å‘˜ã€æ‰‹æªã€æ­¥æªã€æ‰‹å¥—ç­‰ç±»åˆ«ï¼‰")
    parser.add_argument("--token", default=API_TOKEN, help="CSQAQ API Token")
    parser.add_argument("--items", nargs="+", help="æŒ‡å®šè¦è®°å½•çš„ç‰©å“ç±»å‹ï¼ˆé»˜è®¤å…¨éƒ¨ï¼‰")
    parser.add_argument("--category", choices=["åŒ•é¦–", "æ¢å‘˜", "æ‰‹æª", "æ­¥æª", "æ‰‹å¥—"], help="æŒ‡å®šè¦å¤„ç†çš„ç‰©å“ç±»åˆ«")
    parser.add_argument("--dataset-dir", default="./dataset", help="æ•°æ®é›†ç›®å½•")
    parser.add_argument("--test", action="store_true", help="æµ‹è¯•æ¨¡å¼ï¼šæ¯ä¸ªç‰©å“ç±»å‹éšæœºé€‰æ‹©1ä¸ªç‰©å“")
    parser.add_argument("--max-items", type=int, default=None, help="æµ‹è¯•æ¨¡å¼ä¸‹æœç´¢çš„æœ€å¤§ç‰©å“æ•°é‡ï¼ˆé»˜è®¤Noneè¡¨ç¤ºå¤„ç†æ‰€æœ‰å•†å“ï¼‰")
    parser.add_argument("--refresh-cache", action="store_true", help="åˆ·æ–°ç¼“å­˜ï¼Œé‡æ–°æœç´¢æ‰€æœ‰å•†å“")
    parser.add_argument("--use-cache", action="store_true", help="å¼ºåˆ¶ä½¿ç”¨ç¼“å­˜ï¼Œä¸è¿›è¡Œæœç´¢")
    parser.add_argument("--multithread", action="store_true", help="å¯ç”¨å¤šçº¿ç¨‹å¤„ç†")
    parser.add_argument("--max-workers", type=int, default=DEFAULT_MAX_WORKERS, help=f"å¤šçº¿ç¨‹æ¨¡å¼ä¸‹æœ€å¤§å·¥ä½œçº¿ç¨‹æ•°ï¼ˆé»˜è®¤{DEFAULT_MAX_WORKERS}ï¼‰")
    parser.add_argument("--no-template-filter", action="store_true", help="ç¦ç”¨æ¨¡ç‰ˆç­›é€‰ï¼Œå¤„ç†æ‰€æœ‰å•†å“")
    
    args = parser.parse_args()
    
    if not args.token:
        raise SystemExit("éœ€è¦æä¾›API Token")
    
    # è®°å½•æ•°æ®
    builder = ItemDatabaseBuilder(
        args.token, 
        use_multithreading=args.multithread, 
        max_workers=args.max_workers,
        enable_template_filter=not args.no_template_filter
    )
    # åªæœ‰åœ¨ç”¨æˆ·æ˜ç¡®æŒ‡å®šdataset-dirå‚æ•°æ—¶æ‰è¦†ç›–é»˜è®¤è®¾ç½®
    if args.dataset_dir != "./dataset":  # å¦‚æœç”¨æˆ·æŒ‡å®šäº†è‡ªå®šä¹‰è·¯å¾„
        builder.dataset_dir = args.dataset_dir
    builder.refresh_cache = args.refresh_cache
    builder.use_cache = args.use_cache
    
    if args.category:
        # å¤„ç†æŒ‡å®šç±»åˆ«
        item_types = None
        category = args.category
        print(f"ğŸ¯ å¤„ç†ç±»åˆ«ï¼š{category}")
    else:
        # å¤„ç†æŒ‡å®šç‰©å“ç±»å‹æˆ–å…¨éƒ¨
        item_types = args.items
        category = None
        if item_types:
            print(f"ğŸ¯ å¤„ç†ç‰©å“ç±»å‹ï¼š{', '.join(item_types)}")
        else:
            print(f"ğŸ¯ å¤„ç†æ‰€æœ‰ç‰©å“ç±»å‹")
    
    results = builder.run(item_types, test_mode=args.test, max_items=args.max_items, category=category)
    
    print(f"\nğŸ‰ å®æ—¶æ•°æ®è®°å½•å®Œæˆï¼")

if __name__ == "__main__":
    main()
