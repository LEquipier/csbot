# -*- coding: utf-8 -*-
"""
data_builder_butterfly_board_v2.py

ç›®æ ‡ï¼š
- æ„å»ºã€Œè´è¶åˆ€æ¿å—ã€çš„æ¿å—çº§çŸ­çº¿è®­ç»ƒæ•°æ®ï¼ˆ14å¤©ã€T+7ã€å«è´¹ä¸‰é‡è¾¹ç•Œæ ‡ç­¾ï¼‰
- èåˆï¼š
  1) å•å“å¤šå¹³å°å¤šæŒ‡æ ‡ï¼ˆgood_chartï¼‰
  2) æŒ‡æ•°Kçº¿ï¼ˆsub/klineï¼‰â†’ å¸‚åœºå› å­
  3) å®æ—¶æˆäº¤é‡æ¦œï¼ˆvol_data_infoï¼‰â†’ å¹¿åº¦/æƒ…ç»ª
  4) å•å“æˆäº¤é‡å†å² & ç£¨æŸï¼ˆvol_data_detailï¼‰â†’ é‡èƒ½å…œåº• + å“è´¨å› å­

è¾“å‡ºï¼š
- ./dataset/butterfly_board_panel.parquet
- ./dataset/butterfly_board_panel.csv

ä¾èµ–ï¼š
  pip install pandas numpy pyarrow fastparquet tqdm python-dateutil
"""
import os, json, argparse, time
from typing import List, Dict, Any, Tuple, Union
import numpy as np
import pandas as pd
from tqdm import tqdm

# ä½ çš„å®¢æˆ·ç«¯ï¼ˆæ”¾åœ¨é¡¹ç›®å†…ï¼‰ï¼Œéœ€æä¾›ï¼šindex_kline / get_good_id / good_detail / batch_price / good_chart /
#                                  vol_data_info / vol_data_detail
import sys
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from CSQAQ import CsqaqClient
from config import API_TOKEN

# ==================== å¯è°ƒå‚æ•° ====================
PLATFORM_MAP = {1: "BUFF", 2: "YYYP", 3: "Steam"}
DEFAULT_PLATFORMS = [1, 2, 3]  # BUFF + YYYP + Steam

# å¹³å°è´¹ç‡ï¼ˆå¯æŒ‰éœ€è¦†ç›–ï¼›Steam ~15%ï¼ŒBUFF å–å®¶ ~2.5%ï¼‰
PLATFORM_FEES_SELL = {1: 0.025, 2: 0.03, 3: 0.15}  # å–å‡ºè´¹ç‡ï¼Œå‡€å¾— = price*(1-fee) - withdraw
PLATFORM_FEES_BUY  = {1: 0.00,  2: 0.00, 3: 0.00}  # ä¹°å…¥è´¹ç‡ï¼ˆå¤šæ•°åœºæ™¯å¯å¿½ç•¥ï¼‰
WITHDRAW_FEES      = {1: 0.00,  2: 0.00, 3: 0.00}

MIN_HOLD_DAYS   = 7     # T+7
LABEL_HORIZON   = 14    # 14å¤©çŸ­çº¿
TAKE_PROFIT_PCT = 0.08  # æ­¢ç›ˆ +8%ï¼ˆå«è´¹ï¼‰
STOP_LOSS_PCT   = -0.05 # æ­¢æŸ -5%ï¼ˆå«è´¹ï¼‰

# æœºå™¨å­¦ä¹ å¸¸ç”¨æŒ‡æ ‡ï¼ˆgood_chart keysï¼‰
CHART_KEYS = [
    "sell_price", "buy_price",
    "sell_num", "buy_num",
]
PERIOD = "1095"   # 3å¹´
STYLE  = "all_style"

# æ¿å—ç­›é€‰æ¡ä»¶
MIN_PRICE_THRESHOLD = 4000
BUTTERFLY_KEYWORDS = ["è´è¶åˆ€", "Butterfly", "butterfly"]

# ==================== å°å·¥å…· ====================
def ensure_dir(p: str): os.makedirs(p, exist_ok=True)

def safe_get(d: Dict, *ks, default=None):
    cur = d
    for k in ks:
        if isinstance(cur, dict) and k in cur:
            cur = cur[k]
        else:
            return default
    return cur

# ==================== ä»·æ ¼å«è´¹ ====================
def net_sell_proceed(price: Union[float, np.ndarray], platform: int) -> Union[float, np.ndarray]:
    fee = PLATFORM_FEES_SELL.get(platform, 0.0)
    wd  = WITHDRAW_FEES.get(platform, 0.0)
    return price * (1 - fee) - wd

def net_buy_cost(price: Union[float, np.ndarray], platform: int) -> Union[float, np.ndarray]:
    fee = PLATFORM_FEES_BUY.get(platform, 0.0)
    return price * (1 + fee)

# ==================== æ•°æ®æ‹‰å–ï¼šæŒ‡æ•° / æ¦œå• / å•å“æˆäº¤é‡ ====================
def fetch_index_kline(client: CsqaqClient, index_id: int = 1, k_type: str = "1day") -> pd.DataFrame:
    """
    /api/v1/sub/kline?id=1&type=1day
    è¿”å›ï¼šdate, idx_o, idx_h, idx_l, idx_c, idx_v, idx_ret_1d, idx_vol_14d, idx_dd_60d, idx_risk_on
    """
    j = client.index_kline(index_id=index_id, period=k_type)
    arr = safe_get(j, "data", default=[])
    if not arr: return pd.DataFrame()

    df = pd.DataFrame(arr)
    # tï¼ˆå­—ç¬¦ä¸²æ¯«ç§’ï¼‰â†’ date
    df["date"] = pd.to_datetime(df["t"].astype(str), unit="ms", utc=True)\
                    .dt.tz_convert("America/New_York").dt.normalize()
    df = df.rename(columns={"o":"idx_o","h":"idx_h","l":"idx_l","c":"idx_c","v":"idx_v"})
    cols = ["date","idx_o","idx_h","idx_l","idx_c","idx_v"]
    df = df[cols].sort_values("date").reset_index(drop=True)

    df["idx_c"] = pd.to_numeric(df["idx_c"], errors="coerce")
    df["idx_ret_1d"]  = df["idx_c"].pct_change(1)
    df["idx_vol_14d"] = df["idx_ret_1d"].rolling(14).std()
    df["idx_max_60d"] = df["idx_c"].rolling(60).max()
    df["idx_dd_60d"]  = (df["idx_c"] / df["idx_max_60d"] - 1.0)
    df["idx_risk_on"] = ((df["idx_ret_1d"].rolling(5).mean() > 0) &
                         (df["idx_vol_14d"] < df["idx_vol_14d"].median())).astype("Int8")
    return df

def fetch_vol_leaderboard(client: CsqaqClient) -> Tuple[pd.DataFrame, Dict[str,int]]:
    """
    /api/v1/info/vol_data_info (POST)
    è¿”å›ï¼š
      - dfï¼šdate, good_id, vol_statistic, vol_sum_price, vol_avg_price
      - gid->vol_id æ˜ å°„ï¼ˆä»åŸå§‹è¿”å›çš„ 'id' å­—æ®µæå–ï¼‰
    """
    raw = client.vol_data_info()
    arr = safe_get(raw, "data", default=[])
    if not arr: return pd.DataFrame(), {}

    df = pd.DataFrame(arr)
    df = df.rename(columns={
        "good_id": "good_id",
        "statistic": "vol_statistic",
        "sum_price": "vol_sum_price",
        "avg_price": "vol_avg_price",
        "updated_at": "updated_at"
    })
    df["updated_at"] = pd.to_datetime(df["updated_at"], utc=True, errors="coerce")\
                           .dt.tz_convert("America/New_York")
    df["date"] = df["updated_at"].dt.normalize()
    agg = (df.groupby(["date","good_id"])
             .agg(vol_statistic=("vol_statistic","last"),
                  vol_sum_price=("vol_sum_price","last"),
                  vol_avg_price=("vol_avg_price","last"))
             .reset_index())
    gid2volid = {}
    for it in arr:
        gid, vid = it.get("good_id"), it.get("id")
        if gid is not None and vid is not None:
            gid2volid[str(gid)] = int(vid)
    return agg, gid2volid

def fetch_item_volume_series(client: CsqaqClient, vol_id: int, is_weapon: bool = True,
                             start_day: str = "2023-01-01") -> Tuple[pd.DataFrame, pd.DataFrame]:
    """
    /api/v1/info/vol_data_detail (POST)
    è¿”å› (chart_df, wear_df)
      chart_df: date, vol_statistic, vol_avg_price, vol_sum_price
      wear_df : created_at(åˆ°ç§’), price, abrade
    """
    j = client.vol_data_detail(vol_id=vol_id, is_weapon=is_weapon, start_day=start_day)
    ch = safe_get(j, "data", "chart", default=[])
    ls = safe_get(j, "data", "list",  default=[])

    chart_df = pd.DataFrame(ch)
    if not chart_df.empty:
        chart_df["date"] = pd.to_datetime(chart_df["updated_at"], utc=True, errors="coerce")\
                              .dt.tz_convert("America/New_York").dt.normalize()
        chart_df = chart_df.rename(columns={
            "statistic":"vol_statistic",
            "avg_price":"vol_avg_price",
            "sum_price":"vol_sum_price"
        })
        chart_df = chart_df[["date","vol_statistic","vol_avg_price","vol_sum_price"]]

    wear_df = pd.DataFrame(ls)
    if not wear_df.empty:
        wear_df["created_at"] = pd.to_datetime(wear_df["created_at"], utc=True, errors="coerce")\
                                   .dt.tz_convert("America/New_York")
        wear_df["abrade"] = pd.to_numeric(wear_df["abrade"], errors="coerce")
        wear_df = wear_df[["created_at","price","abrade"]]

    return chart_df, wear_df

# ==================== å•å“æ—¶é—´åºåˆ—ï¼ˆgood_chartï¼‰ ====================
def fetch_item_panel(
    client: CsqaqClient,
    good_id: Union[int,str],
    platforms: List[int] = DEFAULT_PLATFORMS,
    chart_keys: List[str] = CHART_KEYS,
    period: str = "1095",
    style: str = "all_style",
    max_retries: int = 6,
    retry_delay: int = 6,
) -> pd.DataFrame:
    """
    ç”¨ /info/chart è·å–å•å“å¤šå¹³å°å¤šæŒ‡æ ‡çš„æ—¥åºåˆ—
    åˆ—ï¼šgood_id, date, {PLATFORM_key...}
    """
    frames = []
    for key in chart_keys:
        for p in platforms:
            ok, ntry, delay = False, 0, retry_delay
            while not ok and ntry < max_retries:
                try:
                    j = client.good_chart(good_id, key=key, platform=p, period=period, style=style)
                    data = safe_get(j, "data", default={})
                    if not data: 
                        break

                    timestamp = data.get("timestamp", [])
                    main_data = data.get("main_data", [])
                    num_data = data.get("num_data", [])

                    if not timestamp: 
                        break

                    df_data = {"timestamp": timestamp}

                    # å¯¹é½ main_data
                    if main_data:
                        m = min(len(timestamp), len(main_data))
                        df_data["timestamp"] = timestamp[:m]
                        df_data["main_data"] = main_data[:m]
                    # å¯¹é½ num_data
                    if num_data:
                        if "main_data" in df_data:
                            m = len(df_data["timestamp"])
                            df_data["num_data"] = num_data[:m]
                        else:
                            m = min(len(timestamp), len(num_data))
                            df_data["timestamp"] = timestamp[:m]
                            df_data["num_data"] = num_data[:m]

                    df = pd.DataFrame(df_data)
                    # æ—¶é—´ â†’ æ—¥
                    df["date"] = pd.to_datetime(df["timestamp"], unit="ms", utc=True)\
                                    .dt.tz_convert("America/New_York").dt.normalize()

                    col_base = f"{PLATFORM_MAP.get(p,f'P{p}')}_{key}"
                    if "main_data" in df.columns:
                        val = pd.to_numeric(df["main_data"], errors="coerce")
                    elif "num_data" in df.columns:
                        val = pd.to_numeric(df["num_data"], errors="coerce")
                    elif "c" in df.columns:
                        val = pd.to_numeric(df["c"], errors="coerce")
                    elif "v" in df.columns:
                        val = pd.to_numeric(df["v"], errors="coerce")
                    else:
                        guess = [c for c in df.columns if c not in ("t","timestamp","date")]
                        val = pd.to_numeric(df[guess[0]], errors="coerce") if guess else pd.Series(dtype=float)

                    if val.isna().all():
                        break

                    df[col_base] = val
                    df["good_id"] = str(good_id)
                    frames.append(df[["good_id","date",col_base]])
                    ok = True
                except Exception:
                    ntry += 1
                    if ntry < max_retries:
                        time.sleep(delay)
                        delay = min(int(delay * 1.5), 30)
                    else:
                        break

    if not frames: 
        print(f"âš ï¸ å•†å“ {good_id} æ²¡æœ‰è·å–åˆ°ä»»ä½•æ•°æ®æ¡†æ¶")
        return pd.DataFrame()

    print(f"ğŸ“Š å•†å“ {good_id} è·å–åˆ° {len(frames)} ä¸ªæ•°æ®æ¡†æ¶")
    print(f"ğŸ“‹ ç¬¬ä¸€ä¸ªæ¡†æ¶åˆ—: {list(frames[0].columns)}")
    
    # åˆå¹¶ + è§„èŒƒä¸ºæ—¥é¢‘ + å‰å‘å¡«å……ï¼ˆä¸äº§ç”Ÿéœ€è¦ droplevel çš„å¤šçº§ç´¢å¼•ï¼‰
    out = frames[0]
    for i, f in enumerate(frames[1:], 1):
        print(f"ğŸ”— åˆå¹¶ç¬¬ {i+1} ä¸ªæ¡†æ¶ï¼Œåˆ—: {list(f.columns)}")
        out = out.merge(f, on=["good_id","date"], how="outer")
    out["date"] = pd.to_datetime(out["date"])
    out = (
        out.groupby(["good_id", pd.Grouper(key="date", freq="1D")]).last()
           .reset_index()
           .sort_values(["good_id","date"])
    )
    out = out.groupby("good_id", group_keys=False).ffill()
    
    # ç¡®ä¿good_idåˆ—å­˜åœ¨
    if "good_id" not in out.columns:
        print(f"âš ï¸ è­¦å‘Šï¼šå¤„ç†åçš„æ•°æ®ç¼ºå°‘good_idåˆ—ï¼Œåˆ—åï¼š{list(out.columns)}")
        # é‡æ–°æ·»åŠ good_idåˆ—
        out["good_id"] = str(good_id)
    
    print(f"âœ… å•†å“ {good_id} å¤„ç†å®Œæˆ: shape={out.shape}, åˆ—={list(out.columns)}")
    return out

# ==================== æ¿å—ï¼šç‰¹å¾å·¥ç¨‹ ====================
def add_price_tech_features(df: pd.DataFrame, price_col: str, prefix: str) -> pd.DataFrame:
    x = pd.to_numeric(df[price_col], errors="coerce")
    df[f"{prefix}_ret_1d"]  = x.pct_change(1)
    df[f"{prefix}_ret_3d"]  = x.pct_change(3)
    df[f"{prefix}_ret_7d"]  = x.pct_change(7)
    df[f"{prefix}_ret_14d"] = x.pct_change(14)

    df[f"{prefix}_vol_7d"]  = df[f"{prefix}_ret_1d"].rolling(7).std()
    df[f"{prefix}_vol_14d"] = df[f"{prefix}_ret_1d"].rolling(14).std()

    ma5  = x.rolling(5).mean()
    ma20 = x.rolling(20).mean()
    df[f"{prefix}_ma_5"]   = ma5
    df[f"{prefix}_ma_20"]  = ma20
    df[f"{prefix}_pos_ma5"]  = x / ma5
    df[f"{prefix}_pos_ma20"] = x / ma20

    # å¸ƒæ—
    ma = x.rolling(20).mean()
    sd = x.rolling(20).std()
    up, dn = ma + 2*sd, ma - 2*sd
    df[f"{prefix}_boll_up"] = up
    df[f"{prefix}_boll_dn"] = dn
    width = (up - dn) / ma.replace(0, np.nan)
    df[f"{prefix}_boll_width"] = width

    # RSI14
    delta = x.diff()
    gain = delta.clip(lower=0).rolling(14).mean()
    loss = (-delta.clip(upper=0)).rolling(14).mean()
    rs = gain / loss.replace(0, np.nan)
    df[f"{prefix}_rsi14"] = 100 - (100 / (1 + rs))
    return df

def add_cross_platform_features(df: pd.DataFrame) -> pd.DataFrame:
    # ä»·å·®/æ¯”å€¼
    if {"BUFF_sell_price","Steam_sell_price"} <= set(df.columns):
        df["buff_steam_diff"]  = df["Steam_sell_price"] - df["BUFF_sell_price"]
        df["buff_steam_ratio"] = df["Steam_sell_price"] / df["BUFF_sell_price"]
    if {"BUFF_sell_price","YYYP_sell_price"} <= set(df.columns):
        df["buff_yyyp_diff"]  = df["YYYP_sell_price"] - df["BUFF_sell_price"]
        df["buff_yyyp_ratio"] = df["YYYP_sell_price"] / df["BUFF_sell_price"]
    # æµåŠ¨æ€§
    if {"BUFF_sell_num","BUFF_buy_num"} <= set(df.columns):
        df["buff_liq_ratio"]  = df["BUFF_buy_num"] / (df["BUFF_sell_num"] + 1)
        df["buff_orders"]     = df["BUFF_buy_num"] + df["BUFF_sell_num"]
    return df

def gen_triple_barrier_labels(
    df: pd.DataFrame,
    trade_platform: int,
    price_col: str,
    take_profit: float = 0.08,
    stop_loss: float = -0.05,
    horizon_days: int = 14,
    min_hold_days: int = 7,
    out_col: str = None
) -> pd.DataFrame:
    """
    ä¸‰é‡è¾¹ç•Œï¼ˆå«è´¹ï¼‰ï¼š
      entry_cost = net_buy_cost(price_t0)
      window t âˆˆ [t0+min_hold, t0+horizon]
      if max_t net_sell_proceed(price_t) / entry_cost - 1 >= TP â†’ +1
      elif min_t net_sell_proceed(price_t) / entry_cost - 1 <= SL â†’ -1
      else 0
    """
    df = df.copy()
    x = pd.to_numeric(df[price_col], errors="coerce").values
    n = len(df)
    label = np.zeros(n, dtype=int)
    for i in range(n):
        p0 = x[i]
        if not np.isfinite(p0): continue
        entry = net_buy_cost(p0, trade_platform)
        start, end = i + min_hold_days, min(i + horizon_days, n - 1)
        if start > end: continue
        window = x[start:end+1]
        rets = (net_sell_proceed(window, trade_platform) - entry) / entry
        tp = np.where(rets >= take_profit)[0]
        sl = np.where(rets <= stop_loss)[0]
        if tp.size > 0: label[i] = 1
        elif sl.size > 0: label[i] = -1
        else: label[i] = 0
    if not out_col:
        out_col = f"label_14d_tp{int(take_profit*100)}_sl{int(abs(stop_loss)*100)}"
    df[out_col] = label
    return df

# ==================== æ¿å—æ„å»ºæµç¨‹ ====================
def fetch_butterfly_universe(client: CsqaqClient,
                             max_pages: int = 6,
                             page_size: int = 50,
                             max_items: int = None) -> List[str]:
    """
    ä½¿ç”¨ get_good_id('è´è¶åˆ€') æœç´¢å…¨é‡ï¼Œå†ç”¨ good_detail/batch_price è¿‡æ»¤ä»·æ ¼â‰¥é˜ˆå€¼
    è¿”å› good_id åˆ—è¡¨ï¼ˆå­—ç¬¦ä¸²ï¼‰
    """
    results = []
    seen = set()
    for page in range(1, max_pages+1):
        try:
            resp = client.get_good_id("è´è¶åˆ€", page_index=page, page_size=page_size)
            data = safe_get(resp, "data", "data", default={})
            if not data: break
            for gid_str, rec in data.items():
                name = rec.get("name", rec.get("market_hash_name","")).lower()
                if any(kw.lower() in name for kw in BUTTERFLY_KEYWORDS):
                    if gid_str not in seen:
                        seen.add(gid_str)
                        results.append(gid_str)
        except Exception:
            continue

    # ä»·æ ¼è¿‡æ»¤ï¼ˆå°½é‡ä½¿ç”¨ good_detail + batch_price å…œåº•ï¼‰
    filtered = []
    for gid in results:
        if max_items and len(filtered) >= max_items:
            break
        try:
            det = client.good_detail(gid)
            info = safe_get(det, "data", default={})
            # å°è¯•å¤šä¸ªä»·æ ¼å­—æ®µ
            candidates = []
            for k in ["buff_sell_price","yyyp_sell_price","steam_sell_price",
                      "buffBuyPrice","yyypBuyPrice","steamBuyPrice",
                      "buffSellPrice","yyypSellPrice","steamSellPrice",
                      "buff_buy_price","yyyp_buy_price","steam_buy_price"]:
                v = info.get(k)
                if v is not None:
                    try: v = float(v)
                    except: v = np.nan
                    if np.isfinite(v) and v > 0: candidates.append(v)
            if not candidates:
                # batch_price å†è¯•
                mhn = safe_get(info, "goods_info","market_hash_name", default=None)
                if mhn:
                    bp = client.batch_price([mhn])
                    succ = safe_get(bp, "data","success", default={})
                    ditem = succ.get(mhn, {})
                    for k in ["buffSellPrice","yyypSellPrice","steamSellPrice",
                              "buffBuyPrice","yyypBuyPrice","steamBuyPrice"]:
                        v = ditem.get(k)
                        if v is not None:
                            try: v = float(v)
                            except: v = np.nan
                            if np.isfinite(v) and v>0: candidates.append(v)
            max_price = max(candidates) if candidates else 0
            if max_price >= MIN_PRICE_THRESHOLD:
                filtered.append(gid)
        except Exception:
            continue
    return filtered

def build_butterfly_board_dataset(
    token: str,
    out_dir: str = "./dataset",
    platforms: List[int] = DEFAULT_PLATFORMS,
    chart_keys: List[str] = CHART_KEYS,
    period: str = "1095",
    style: str = "all_style",
    test_mode: bool = False
) -> pd.DataFrame:
    """
    æ­¥éª¤ï¼š
      A) é€‰å®‡å®™ï¼ˆè´è¶åˆ€ç¬¦åˆä»·ä½çš„ good_idï¼‰
      B) æ‹‰å•å“æ—¶é—´åºåˆ—å¹¶æ¨ªå‘åˆå¹¶ä¸ºã€Œæ¿å—é¢æ¿ã€ï¼ˆé€æ—¥ï¼šæ¯ä¸ª good_id ä¸€è¡Œï¼‰
      C) è®¡ç®—ã€Œæ¿å—æ¨ªæˆªé¢ç»Ÿè®¡ã€ä¸ã€Œå¸‚åœº/å¹¿åº¦/é‡èƒ½å…œåº•ã€å¹¶åˆå¹¶
      D) ç”Ÿæˆå«è´¹ä¸‰é‡è¾¹ç•Œæ ‡ç­¾ï¼ˆä»¥ BUFF å–ä»·ä¸ºå‚è€ƒï¼‰
    """
    ensure_dir(out_dir)
    client = CsqaqClient(api_token=token)

    # ------- A) æ¿å—å®‡å®™ -------
    print("ğŸ” æ„å»ºè´è¶åˆ€å®‡å®™ ...")
    good_ids = fetch_butterfly_universe(
        client, 
        max_pages=2 if test_mode else 8, 
        page_size=20 if test_mode else 50,
        max_items=5 if test_mode else None  # æµ‹è¯•æ¨¡å¼è·å–5ä¸ªï¼Œç”Ÿäº§æ¨¡å¼è·å–æ‰€æœ‰
    )
    if not good_ids: raise RuntimeError("æœªæ‰¾åˆ°è´è¶åˆ€å®‡å®™ï¼ˆè¯·æ£€æŸ¥å…³é”®è¯æˆ–é˜ˆå€¼ï¼‰")
    print(f"âœ… è´è¶åˆ€å€™é€‰æ•°ï¼š{len(good_ids)}")

    # ------- B) æ‹‰å•å“é¢æ¿ -------
    print("ğŸ“¡ æ‹‰å–å•å“æ—¶é—´åºåˆ—ï¼ˆgood_chartï¼‰ ...")
    item_frames = []
    for gid in tqdm(good_ids):
        df = fetch_item_panel(client, gid, platforms=platforms, chart_keys=chart_keys, period=period, style=style)
        if df.empty: 
            continue
        # ä¸ºæ¯ä¸ªå¸¸ç”¨ä»·æ ¼åˆ—æ·»åŠ æŠ€æœ¯ç‰¹å¾
        for p in platforms:
            col = f"{PLATFORM_MAP.get(p,f'P{p}')}_sell_price"
            if col in df.columns:
                df = add_price_tech_features(df, col, prefix=col)
        df = add_cross_platform_features(df)
        item_frames.append(df)

    if not item_frames:
        raise RuntimeError("æœªè·å–åˆ°ä»»ä½•å•å“æ—¶é—´åºåˆ—ã€‚")

    print(f"ğŸ”— å‡†å¤‡åˆå¹¶ {len(item_frames)} ä¸ªå•†å“çš„æ•°æ®æ¡†æ¶")
    for i, df in enumerate(item_frames):
        print(f"ğŸ“Š å•†å“ {i+1} æ¡†æ¶: shape={df.shape}, åˆ—={list(df.columns)}")
    
    panel = pd.concat(item_frames, ignore_index=True)
    print(f"ğŸ“‹ åˆå¹¶åé¢æ¿: shape={panel.shape}, åˆ—={list(panel.columns)}")
    
    # ç¡®ä¿good_idåˆ—å­˜åœ¨
    if "good_id" not in panel.columns:
        raise RuntimeError("åˆå¹¶åçš„æ•°æ®ç¼ºå°‘good_idåˆ—")
    panel["good_id"] = panel["good_id"].astype(str)
    panel = panel.sort_values(["good_id","date"]).drop_duplicates(["good_id","date"])

    # ------- C1) æŒ‡æ•°Kçº¿ï¼ˆå¸‚åœºå› å­ï¼‰ -------
    print("ğŸ“ˆ åˆå¹¶æŒ‡æ•°Kçº¿ï¼ˆå¸‚åœºå› å­ï¼‰ ...")
    idx_df = fetch_index_kline(client, index_id=1, k_type="1day")
    if not idx_df.empty:
        panel = panel.merge(idx_df, on="date", how="left")

    # ------- C2) å®æ—¶æˆäº¤é‡æ¦œï¼ˆå¹¿åº¦/æƒ…ç»ªï¼‰ -------
    print("ğŸ“Š åˆå¹¶å½“æ—¥æ¦œå•ï¼ˆå¹¿åº¦/æƒ…ç»ªï¼‰ ...")
    lb_df, gid2volid = fetch_vol_leaderboard(client)
    if not lb_df.empty:
        lb_df["good_id"] = lb_df["good_id"].astype(str)
        panel = panel.merge(lb_df, on=["date","good_id"], how="left")
        # å¹¿åº¦ï¼šå½“æ—¥ä¸Šæ¶¨å æ¯”ï¼ˆæŒ‰ BUFF_sell_price_ret_1dï¼‰
        ret_col = "BUFF_sell_price_ret_1d" if "BUFF_sell_price_ret_1d" in panel.columns else None
        if ret_col:
            breadth = (panel[["date","good_id",ret_col]].dropna()
                       .assign(up=lambda d: (d[ret_col] > 0).astype(int))
                       .groupby("date")["up"].mean().to_frame("breadth_up_all").reset_index())
            panel = panel.merge(breadth, on="date", how="left")

    # ------- C3) å•å“æˆäº¤é‡å†å²å…œåº•ï¼ˆä»…ç¼ºå¤±æ—¶ï¼‰ -------
    print("ğŸ§© å¯¹ç¼ºå¤±é‡èƒ½è¿›è¡Œå…œåº•ï¼ˆvol_data_detailï¼‰ ...")
    # å¦‚æœä½ åç»­æŠŠ daily_volume æ‹‰åˆ°äº†é¢æ¿é‡Œï¼Œå¯åœ¨è¿™é‡ŒæŒ‰éœ€å…œåº•ï¼›å½“å‰ç”¨ vol_statistic ä½œä¸ºæ€»é‡å‚è€ƒ
    if "vol_statistic" not in panel.columns and gid2volid:
        # å¯é€‰ï¼šå¯¹å°‘é‡ä»£è¡¨æ€§IDåšå…œåº•ï¼Œé¿å…è¿‡å¤šè¯·æ±‚
        to_fix = list(gid2volid.keys())[:30]
        for gid in tqdm(to_fix):
            vid = gid2volid.get(gid)
            if not vid: continue
            chart_df, _ = fetch_item_volume_series(client, vol_id=vid, is_weapon=True, start_day="2023-01-01")
            if chart_df.empty: continue
            chart_df["good_id"] = str(gid)
            panel = panel.merge(chart_df, on=["good_id","date"], how="left", suffixes=("","_from_volapi"))
            if "total_daily_volume" not in panel.columns:
                panel["total_daily_volume"] = panel["vol_statistic"]
            else:
                panel["total_daily_volume"] = panel["total_daily_volume"].fillna(panel["vol_statistic"])

    # ------- C4) æ¿å—æ¨ªæˆªé¢ç»Ÿè®¡ï¼ˆæŒ‰æ—¥èšåˆï¼‰ -------
    print("ğŸ§® è®¡ç®—æ¿å—æ¨ªæˆªé¢ç»Ÿè®¡ ...")
    ref_price = "BUFF_sell_price" if "BUFF_sell_price" in panel.columns else None
    if ref_price:
        grp = panel[["date","good_id",ref_price]].dropna()
        agg = (grp.groupby("date")[ref_price]
               .agg(board_median="median", board_mean="mean", board_std="std", board_min="min", board_max="max")
               .reset_index())
        panel = panel.merge(agg, on="date", how="left")
        panel["board_zscore"] = (panel[ref_price] - panel["board_mean"]) / panel["board_std"]

    # ------- D) ç”Ÿæˆå«è´¹ä¸‰é‡è¾¹ç•Œæ ‡ç­¾ï¼ˆä»¥ BUFF ä¸ºä¾‹ï¼‰ -------
    print("ğŸ·ï¸ ç”Ÿæˆå«è´¹ä¸‰é‡è¾¹ç•Œæ ‡ç­¾ ...")
    if ref_price and panel[ref_price].notna().any():
        panel = (panel.sort_values(["good_id","date"])
                       .groupby("good_id", group_keys=False)
                       .apply(lambda d: gen_triple_barrier_labels(
                           d, trade_platform=1, price_col=ref_price,
                           take_profit=0.08, stop_loss=-0.05,
                           horizon_days=14, min_hold_days=7)))
    else:
        print("âš ï¸ ç¼ºå°‘å‚è€ƒä»·æ ¼åˆ—ï¼Œè·³è¿‡æ ‡ç­¾ã€‚")

    # æ¸…ç†ä¸ä¿å­˜
    panel = panel.sort_values(["good_id","date"]).reset_index(drop=True)
    print("\nğŸ” æ•°æ®è´¨é‡ï¼š")
    print(f"  æ€»è¡Œæ•°: {len(panel)}")
    print(f"  å•†å“æ•°: {panel['good_id'].nunique()}")
    print(f"  æ—¶é—´èŒƒå›´: {panel['date'].min()} â†’ {panel['date'].max()}")
    print(f"  åˆ—æ•°: {panel.shape[1]}")

    ensure_dir(out_dir)
    out_csv = os.path.join(out_dir, "butterfly_board_panel.csv")
    out_pq  = os.path.join(out_dir, "butterfly_board_panel.parquet")
    panel.to_csv(out_csv, index=False)
    try:
        panel.to_parquet(out_pq, index=False)
    except Exception as e:
        print(f"âš ï¸ ä¿å­˜ Parquet å¤±è´¥ï¼š{e}")

    print(f"âœ… ä¿å­˜ï¼š{out_csv}")
    print(f"âœ… ä¿å­˜ï¼š{out_pq}ï¼ˆå¦‚å¤±è´¥å·²å¿½ç•¥ï¼‰")
    return panel

# ==================== CLI ====================
if __name__ == "__main__":
    ap = argparse.ArgumentParser()
    ap.add_argument("--token", default=API_TOKEN, help="CSQAQ API Token")
    ap.add_argument("--out", default="./dataset", help="è¾“å‡ºç›®å½•")
    ap.add_argument("--platforms", default="1,2,3", help="å¹³å°ï¼ˆ1=BUFF,2=YYYP,3=Steamï¼‰")
    ap.add_argument("--period", default="1095", help="å†å²å‘¨æœŸï¼ˆå¦‚ 365/1095ï¼‰")
    ap.add_argument("--style", default="all_style", help="å›¾è¡¨æ ·å¼ï¼ˆé»˜è®¤ all_styleï¼‰")
    ap.add_argument("--take_profit", type=float, default=0.08, help="æ­¢ç›ˆæ¯”ä¾‹ï¼ˆå«è´¹ï¼‰ï¼Œå¦‚ 0.08")
    ap.add_argument("--stop_loss", type=float, default=-0.05, help="æ­¢æŸæ¯”ä¾‹ï¼ˆå«è´¹ï¼‰ï¼Œå¦‚ -0.05")
    ap.add_argument("--min_hold", type=int, default=7, help="æœ€çŸ­æŒæœ‰å¤©æ•°ï¼ˆT+7 â†’ 7ï¼‰")
    ap.add_argument("--horizon", type=int, default=14, help="æ ‡ç­¾çª—å£å¤©æ•°ï¼ˆ14ï¼‰")
    ap.add_argument("--test", action="store_true", help="æµ‹è¯•æ¨¡å¼ï¼ˆå°æ ·æœ¬ï¼‰")
    args = ap.parse_args()

    if not args.token:
        raise SystemExit("éœ€è¦ --token æˆ–è®¾ç½®ç¯å¢ƒå˜é‡ CSQAQ_TOKEN")

    # ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°
    period = args.period
    style = args.style
    take_profit = args.take_profit
    stop_loss = args.stop_loss
    min_hold = args.min_hold
    horizon = args.horizon

    pf = [int(x.strip()) for x in args.platforms.split(",") if x.strip()]

    df = build_butterfly_board_dataset(
        token=args.token,
        out_dir=args.out,
        platforms=pf,
        chart_keys=CHART_KEYS,
        period=args.period,
        style=args.style,
        test_mode=args.test
    )
    print(f"å®Œæˆã€‚rows={len(df)}, goods={df['good_id'].nunique()}")